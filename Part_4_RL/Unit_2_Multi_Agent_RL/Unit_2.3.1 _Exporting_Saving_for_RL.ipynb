{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Exporting and saving ML models"],"metadata":{"id":"7E9pDrYRZ0yw"}},{"cell_type":"markdown","source":["Exporting and saving ML models for reinforcement learning is a crucial step in the model development process, and allows you to preserve and reuse the state of a model after training, and deploy it in different environments. This guide explains how to export and save ML models, focusing on various aspects and formats comonly used."],"metadata":{"id":"T86N7LHnZ4Pw"}},{"cell_type":"markdown","source":["### Saving RL Models\n","- Saving preserves the model's architecture, trained weights and often associated configuration information (like hyperparameters) so that you can reuse the model\n","- Intended for future use within the same framework or closely related environments where you started training\n","\n","### Common Formats for Saving Models\n","\n","PyTorch (.pth or .pt): Saves either the entire model or just the state dictionary, including the weights and biases but not the architecture.\n","\n","Safetensors: A more safer way of pickling tensors and weights that is still fast.\n"],"metadata":{"id":"T7TW-RwJcaxz"}},{"cell_type":"markdown","source":["### Creating a dummy environment\n","\n","Some of the parameters in the RL models are closely interrelated with an environment, so we will load MountainCar-v0 to initialise these parameters"],"metadata":{"id":"Q82PEs8DeU8x"}},{"cell_type":"code","source":["!pip install torchrl==0.7.0 gymnasium==0.29 tqdm matplotlib av tensordict==0.7.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HGQKWCt4ehS0","executionInfo":{"status":"ok","timestamp":1746508609884,"user_tz":-480,"elapsed":110927,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}},"outputId":"d79ad04f-f5ee-40be-d2a3-cf089aa98077"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchrl==0.7.0\n","  Downloading torchrl-0.7.0-cp311-cp311-manylinux1_x86_64.whl.metadata (39 kB)\n","Collecting gymnasium==0.29\n","  Downloading gymnasium-0.29.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Collecting av\n","  Downloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n","Collecting tensordict==0.7.2\n","  Downloading tensordict-0.7.2-cp311-cp311-manylinux1_x86_64.whl.metadata (9.1 kB)\n","Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchrl==0.7.0) (2.6.0+cu124)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchrl==0.7.0) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchrl==0.7.0) (24.2)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from torchrl==0.7.0) (3.1.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29) (4.13.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29) (0.0.4)\n","Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict==0.7.2) (3.10.18)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.6.0->torchrl==0.7.0) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.6.0->torchrl==0.7.0) (3.0.2)\n","Downloading torchrl-0.7.0-cp311-cp311-manylinux1_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gymnasium-0.29.0-py3-none-any.whl (953 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.8/953.8 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensordict-0.7.2-cp311-cp311-manylinux1_x86_64.whl (400 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, av, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, tensordict, torchrl\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: gymnasium\n","    Found existing installation: gymnasium 1.1.1\n","    Uninstalling gymnasium-1.1.1:\n","      Successfully uninstalled gymnasium-1.1.1\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed av-14.3.0 gymnasium-0.29.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tensordict-0.7.2 torchrl-0.7.0\n"]}]},{"cell_type":"code","source":["from torchrl.envs import (\n","    Compose, DoubleToFloat,\n","    ObservationNorm, StepCounter,\n","    TransformedEnv, set_exploration_type,\n",")\n","from torchrl.modules import ProbabilisticActor, ValueOperator\n","from torchrl.objectives import ClipPPOLoss\n","from torchrl.objectives.value import GAE\n","from torch.distributions import Categorical\n","from tensordict.nn import TensorDictModule, TensorDictSequential\n","from torch import nn\n","from torchrl.envs import GymWrapper\n","import gymnasium as gym\n","import torch\n","base_env = gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\")\n","env = GymWrapper(\n","    gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\"), categorical_action_encoding=  True, device = \"cpu\"\n",")\n","\n","env = TransformedEnv(env, Compose(\n","    DoubleToFloat(),\n","    StepCounter(),\n","))\n","\n","print(env.action_spec)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"138M8Mpmefb7","executionInfo":{"status":"ok","timestamp":1746509593883,"user_tz":-480,"elapsed":201,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}},"outputId":"904208d4-26b8-440b-a29e-d4a94ae37000"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Categorical(\n","    shape=torch.Size([]),\n","    space=CategoricalBox(n=3),\n","    device=cpu,\n","    dtype=torch.int64,\n","    domain=discrete)\n"]}]},{"cell_type":"markdown","source":["### Defining a simple model for RL"],"metadata":{"id":"K9uO_E-KeSYQ"}},{"cell_type":"code","source":["num_cells = 64\n","\n","# Simple Actor-Critic Setup\n","\n","# You can skip these if you want, these are the underlying neural networks.\n","# Since we are using a Discrete policy, we need to use a Softmax to transform the outputs into action probabilities.\n","actor_net = nn.Sequential(\n","    nn.LazyLinear(num_cells),\n","    nn.Tanh(),\n","    nn.LazyLinear(num_cells),\n","    nn.Tanh(),\n","    nn.LazyLinear(num_cells),\n","    nn.Tanh(),\n","    nn.LazyLinear(3),\n","    nn.Softmax(dim = -1)\n",")\n","\n","\n","value_net = nn.Sequential(\n","    nn.LazyLinear(num_cells),\n","    nn.Tanh(),\n","    nn.LazyLinear(num_cells),\n","    nn.Tanh(),\n","    nn.LazyLinear(num_cells),\n","    nn.Tanh(),\n","    nn.LazyLinear(1),\n",")\n","\n","\n","# Actor Module\n","policy_module = ProbabilisticActor(\n","    module = TensorDictModule(\n","        actor_net, in_keys=[\"observation\"], out_keys=[\"logits\"]\n","    ),\n","    spec=env.action_spec,\n","    in_keys=[\"logits\"],\n","    distribution_class=Categorical,\n","    return_log_prob=True,\n","    # we'll need the log-prob for the numerator of the importance weights\n",")\n","\n","# Critic Module\n","value_module = ValueOperator(\n","    module=value_net,\n","    in_keys=[\"observation\"],\n",")\n"],"metadata":{"id":"LdM_JVT4dj8Q","executionInfo":{"status":"ok","timestamp":1746509594792,"user_tz":-480,"elapsed":41,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"id":"By-jbQTKY4ne","executionInfo":{"status":"ok","timestamp":1746509595284,"user_tz":-480,"elapsed":83,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}}},"outputs":[],"source":["# Saving models in Pytorch\n","torch.save(policy_module, 'policy_module.pth')\n","torch.save(value_module, 'value_module.pth')\n","\n","#Saving model state dictionaries\n","#Make sure you run a dummy pass through them to initialise the values\n","dummy_td = env.reset()\n","dummy_observation = dummy_td[\"observation\"].unsqueeze(0)\n","# Run a dummy forward pass through the actor network\n","# If your actor network expects the observation in a dict form, wrap it accordingly.\n","_ = actor_net(dummy_observation)\n","\n","# Similarly, run a dummy forward pass through the value (critic) network\n","_ = value_net(dummy_observation)\n","\n","torch.save(policy_module.state_dict(), 'loss_module_state_dict.pth')\n","torch.save(value_module.state_dict(), 'loss_module_state_dict.pth')\n","\n","\n","\n"]},{"cell_type":"markdown","source":["### Exporting Models\n","- Exporting a model converts it into a representaiton suitable for deployment in production environments or for use across different frameworks\n","- Involves optimizations or format changes for better inference speed and compatability"],"metadata":{"id":"xukIKLidhdAo"}},{"cell_type":"code","source":["!pip install onnx onnxruntime onnxscript"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F32SUPhDhrXm","executionInfo":{"status":"ok","timestamp":1746509601506,"user_tz":-480,"elapsed":5383,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}},"outputId":"44b414c3-220e-43af-fb30-5f3feae3e34f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (1.17.0)\n","Requirement already satisfied: onnxruntime in /usr/local/lib/python3.11/dist-packages (1.21.1)\n","Requirement already satisfied: onnxscript in /usr/local/lib/python3.11/dist-packages (0.2.5)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n","Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from onnxscript) (4.13.2)\n","Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.11/dist-packages (from onnxscript) (0.4.1)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime) (10.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n"]}]},{"cell_type":"code","source":["from pprint import pprint\n","### Exporting normally through PyTorch routines\n","\n","policy_transform = TensorDictSequential(\n","    env.transform[: -1], #Last transform is a step counter which we don't need\n","    policy_module.requires_grad_(\n","        False\n","    ), # Using the explorative version of the policy for teaching purposes\n",")\n","\n","fake_td = env.base_env.fake_tensordict()\n","obs = fake_td['observation']\n","with set_exploration_type(\"DETERMINISTIC\"):\n","    exported = torch.export.export(\n","    policy_transform.select_out_keys(\"action\"),\n","    args=(),\n","    kwargs={'observation':obs},\n","    strict = False\n","  )\n","\n","print(\"Deterministic Policy\")\n","exported.graph_module.print_readable()\n","\n","### We can run outputs through the exported module as well\n","output = exported.module()(observation=obs)\n","print(\"Exported Module Output\")\n","print(output)"],"metadata":{"id":"jybLB4iHhwbH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746509601784,"user_tz":-480,"elapsed":277,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}},"outputId":"ada473fe-ff64-462a-bc49-d224146bb432"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Deterministic Policy\n","class GraphModule(torch.nn.Module):\n","    def forward(self, p_module_1_module_0_module_0_weight: \"f32[64, 2]\", p_module_1_module_0_module_0_bias: \"f32[64]\", p_module_1_module_0_module_2_weight: \"f32[64, 64]\", p_module_1_module_0_module_2_bias: \"f32[64]\", p_module_1_module_0_module_4_weight: \"f32[64, 64]\", p_module_1_module_0_module_4_bias: \"f32[64]\", p_module_1_module_0_module_6_weight: \"f32[3, 64]\", p_module_1_module_0_module_6_bias: \"f32[3]\", kwargs_observation: \"f32[2]\"):\n","         # File: /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)\n","        linear: \"f32[64]\" = torch.ops.aten.linear.default(kwargs_observation, p_module_1_module_0_module_0_weight, p_module_1_module_0_module_0_bias);  kwargs_observation = p_module_1_module_0_module_0_weight = p_module_1_module_0_module_0_bias = None\n","        \n","         # File: /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:392 in forward, code: return torch.tanh(input)\n","        tanh: \"f32[64]\" = torch.ops.aten.tanh.default(linear);  linear = None\n","        \n","         # File: /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)\n","        linear_1: \"f32[64]\" = torch.ops.aten.linear.default(tanh, p_module_1_module_0_module_2_weight, p_module_1_module_0_module_2_bias);  tanh = p_module_1_module_0_module_2_weight = p_module_1_module_0_module_2_bias = None\n","        \n","         # File: /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:392 in forward, code: return torch.tanh(input)\n","        tanh_1: \"f32[64]\" = torch.ops.aten.tanh.default(linear_1);  linear_1 = None\n","        \n","         # File: /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)\n","        linear_2: \"f32[64]\" = torch.ops.aten.linear.default(tanh_1, p_module_1_module_0_module_4_weight, p_module_1_module_0_module_4_bias);  tanh_1 = p_module_1_module_0_module_4_weight = p_module_1_module_0_module_4_bias = None\n","        \n","         # File: /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:392 in forward, code: return torch.tanh(input)\n","        tanh_2: \"f32[64]\" = torch.ops.aten.tanh.default(linear_2);  linear_2 = None\n","        \n","         # File: /usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py:125 in forward, code: return F.linear(input, self.weight, self.bias)\n","        linear_3: \"f32[3]\" = torch.ops.aten.linear.default(tanh_2, p_module_1_module_0_module_6_weight, p_module_1_module_0_module_6_bias);  tanh_2 = p_module_1_module_0_module_6_weight = p_module_1_module_0_module_6_bias = None\n","        \n","         # File: /usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py:1672 in forward, code: return F.softmax(input, self.dim, _stacklevel=5)\n","        softmax: \"f32[3]\" = torch.ops.aten.softmax.int(linear_3, -1);  linear_3 = None\n","        \n","         # File: /usr/local/lib/python3.11/dist-packages/tensordict/nn/probabilistic.py:601 in forward, code: dist = self.get_dist(tensordict)\n","        logsumexp: \"f32[1]\" = torch.ops.aten.logsumexp.default(softmax, [-1], True)\n","        sub: \"f32[3]\" = torch.ops.aten.sub.Tensor(softmax, logsumexp);  softmax = logsumexp = None\n","        \n","         # File: /usr/local/lib/python3.11/dist-packages/tensordict/nn/probabilistic.py:603 in forward, code: out_tensors = self._dist_sample(dist, interaction_type=interaction_type())\n","        softmax_1: \"f32[3]\" = torch.ops.aten.softmax.int(sub, -1)\n","        argmax: \"i64[]\" = torch.ops.aten.argmax.default(softmax_1, -1);  softmax_1 = None\n","        \n","         # File: /usr/local/lib/python3.11/dist-packages/tensordict/nn/probabilistic.py:643 in forward, code: log_prob = dist.log_prob(*out_tensors)\n","        to: \"i64[]\" = torch.ops.aten.to.dtype(argmax, torch.int64);  argmax = None\n","        unsqueeze: \"i64[1]\" = torch.ops.aten.unsqueeze.default(to, -1)\n","        broadcast_tensors = torch.ops.aten.broadcast_tensors.default([unsqueeze, sub]);  unsqueeze = sub = None\n","        getitem: \"i64[3]\" = broadcast_tensors[0]\n","        getitem_1: \"f32[3]\" = broadcast_tensors[1];  broadcast_tensors = None\n","        slice_1: \"i64[1]\" = torch.ops.aten.slice.Tensor(getitem, 0, 0, 1);  getitem = None\n","        gather: \"f32[1]\" = torch.ops.aten.gather.default(getitem_1, -1, slice_1);  getitem_1 = slice_1 = None\n","        squeeze: \"f32[]\" = torch.ops.aten.squeeze.dim(gather, -1);  gather = squeeze = None\n","        return (to,)\n","        \n","Exported Module Output\n","tensor(0)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/fx/experimental/proxy_tensor.py:1766: UserWarning: Unable to find the path of the module TensorDictSequential(\n","    module=ModuleList(\n","      (0): TensorDictModule(\n","          module=Sequential(\n","            (0): Linear(in_features=2, out_features=64, bias=True)\n","            (1): Tanh()\n","            (2): Linear(in_features=64, out_features=64, bias=True)\n","            (3): Tanh()\n","            (4): Linear(in_features=64, out_features=64, bias=True)\n","            (5): Tanh()\n","            (6): Linear(in_features=64, out_features=3, bias=True)\n","            (7): Softmax(dim=-1)\n","          ),\n","          device=cpu,\n","          in_keys=['observation'],\n","          out_keys=['logits'])\n","    ),\n","    device=cpu,\n","    in_keys=['observation'],\n","    out_keys=['logits']). This might be because the module was not properly registered as a submodule, which is not good practice. We will trace through the module without recording stack information.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/tensordict/nn/probabilistic.py:460: DeprecationWarning: You are querying the log-probability key of a SafeProbabilisticModule where the composite_lp_aggregate has not been set and the log-prob key has not been chosen. Currently, it is assumed that composite_lp_aggregate() will return True: the log-probs will be aggregated in a sample_log_prob entry. From v0.9, this behaviour will be changed and individual log-probs will be written in `('path', 'to', 'leaf', '<sample_name>_log_prob')`. To prepare for this change, call `set_composite_lp_aggregate(mode: bool).set()` at the beginning of your script (or set the COMPOSITE_LP_AGGREGATE env variable). Use mode=True to keep the current behaviour, and mode=False to use per-leaf log-probs.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["import torch.onnx\n","import onnxruntime\n","\n","\n","### Using onnx to export\n","with set_exploration_type(\"DETERMINISTIC\"):\n","  obs = fake_td['observation']\n","  onnx_policy = torch.onnx.dynamo_export(policy_transform, observation = obs)\n","\n","\n","### Save ONNX model\n","onnx_file_path = \"policy.onnx\"\n","onnx_policy.save(onnx_file_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oACsqKKcX_Of","outputId":"b099d365-7da9-45f7-e4d1-426828409968"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/onnx/_internal/_exporter_legacy.py:101: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["### Loading a Model"],"metadata":{"id":"05_osUXlhEJ5"}},{"cell_type":"code","source":["adv_model = torch.load(\"policy_module.pth\", weights_only = False)\n","loss_model = torch.load(\"value_module.pth\", weights_only= False)"],"metadata":{"id":"9xvgFOEZgoBA","executionInfo":{"status":"ok","timestamp":1746508659502,"user_tz":-480,"elapsed":42,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["### Loading via ONNX\n","ort_session = onnxruntime.InferenceSession(\n","    onnx_file_path, providers=[\"CPUExecutionProvider\"]\n",")\n","\n","onnxruntime_input = {ort_session.get_inputs()[0].name: obs.numpy()}\n","onnx_policy = ort_session.run(None, onnxruntime_input)"],"metadata":{"id":"ZoLTPyAihNWC","executionInfo":{"status":"ok","timestamp":1746508659551,"user_tz":-480,"elapsed":47,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Running a rollout with ONNX:\n","from torchrl._utils import timeit\n","import numpy as np\n","\n","def onnx_policy(screen_obs: np.ndarray) -> int:\n","    onnxruntime_input = {ort_session.get_inputs()[0].name: obs}\n","    onnxruntime_outputs = ort_session.run(None, onnxruntime_input)\n","    action = int(onnxruntime_outputs[0])\n","    return action\n","\n","\n","with timeit(\"ONNX rollout\"):\n","    num_steps = 1000\n","    td = base_env.reset()\n","    print(td)\n","    for _ in range(num_steps):\n","        obs = td[0]\n","        action = onnx_policy(obs)\n","        reward = base_env.step(action)\n","\n","with timeit(\"TorchRL version\"), torch.no_grad(), set_exploration_type(\"DETERMINISTIC\"):\n","    env.rollout(num_steps, policy_module)\n","\n","print(timeit.print())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-hrQEezCdKR0","executionInfo":{"status":"ok","timestamp":1746508660637,"user_tz":-480,"elapsed":1080,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}},"outputId":"e3e435ac-5889-4b1d-c3bc-1da8cfc9a393"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["(array([-0.5069718,  0.       ], dtype=float32), {})\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/tensordict/nn/probabilistic.py:460: DeprecationWarning: You are querying the log-probability key of a SafeProbabilisticModule where the composite_lp_aggregate has not been set and the log-prob key has not been chosen. Currently, it is assumed that composite_lp_aggregate() will return True: the log-probs will be aggregated in a sample_log_prob entry. From v0.9, this behaviour will be changed and individual log-probs will be written in `('path', 'to', 'leaf', '<sample_name>_log_prob')`. To prepare for this change, call `set_composite_lp_aggregate(mode: bool).set()` at the beginning of your script (or set the COMPOSITE_LP_AGGREGATE env variable). Use mode=True to keep the current behaviour, and mode=False to use per-leaf log-probs.\n","  warnings.warn(\n","2025-05-06 05:17:40,364 [torchrl][INFO] ONNX rollout took 210.5 msec (total = 0.21054577827453613 sec)\n","2025-05-06 05:17:40,367 [torchrl][INFO] TorchRL version took 672.4 msec (total = 0.6723911762237549 sec)\n"]},{"output_type":"stream","name":"stdout","text":["ONNX rollout took 210.5 msec (total = 0.21054577827453613 sec)\n","TorchRL version took 672.4 msec (total = 0.6723911762237549 sec)\n"]}]}]}