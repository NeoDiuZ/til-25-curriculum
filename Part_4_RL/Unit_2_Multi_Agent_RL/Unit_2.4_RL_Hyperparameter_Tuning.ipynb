{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8e685e9ef862476eb869c38bcf491552":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4119a2a26e1943fc8b4148298286adb8","IPY_MODEL_2cab29f57c7342c8bd92d5634c19aea2","IPY_MODEL_f58b4aa33d5f40a2ac9d52dd2a6d530f"],"layout":"IPY_MODEL_103d9eeae2b747d6828834a71db83e41"}},"4119a2a26e1943fc8b4148298286adb8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d35e26a2bb034bef9b3ff380ec4a7cad","placeholder":"​","style":"IPY_MODEL_3602de3b944d49b9b04cf78d27d57d29","value":"Steps: 20000, archer: 1.44, knight: 0.00: 100%"}},"2cab29f57c7342c8bd92d5634c19aea2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30a347b06fc245c6be38675b7db7bcb5","max":20000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5c39313d2f1d4f94925e2bbc7f215551","value":20000}},"f58b4aa33d5f40a2ac9d52dd2a6d530f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_216378eb10d04c078376e85abb9f26b1","placeholder":"​","style":"IPY_MODEL_e1589ba5a48b4ec586c0ef8502bda37a","value":" 20000/20000 [03:30&lt;00:00, 98.27it/s]"}},"103d9eeae2b747d6828834a71db83e41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d35e26a2bb034bef9b3ff380ec4a7cad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3602de3b944d49b9b04cf78d27d57d29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30a347b06fc245c6be38675b7db7bcb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c39313d2f1d4f94925e2bbc7f215551":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"216378eb10d04c078376e85abb9f26b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1589ba5a48b4ec586c0ef8502bda37a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04afb5a50e8f418eb9819974455c0ea0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30b2f477f33142f5ba580c2ac28b9fea","IPY_MODEL_5310e81202224daca61255e303564e22","IPY_MODEL_701ff12605fa48108032d9361e4ca26f"],"layout":"IPY_MODEL_a21eed07b208462f8688935f8d4f843d"}},"30b2f477f33142f5ba580c2ac28b9fea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c220f50239f4cc1bed16cd9e098e5fa","placeholder":"​","style":"IPY_MODEL_4fa2804eaeb8497993813d7d7d5572b8","value":"Steps: 20000, archer: 1.94, knight: 0.07: 100%"}},"5310e81202224daca61255e303564e22":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c925342e556c4efab636bdecc5d78323","max":20000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7027bdc0330d43f3a0e7899c45febde7","value":20000}},"701ff12605fa48108032d9361e4ca26f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43c964640abd4894bcc41673dac1decc","placeholder":"​","style":"IPY_MODEL_392633a68c95411699f9949a67bb54d4","value":" 20000/20000 [03:41&lt;00:00, 97.86it/s]"}},"a21eed07b208462f8688935f8d4f843d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c220f50239f4cc1bed16cd9e098e5fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4fa2804eaeb8497993813d7d7d5572b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c925342e556c4efab636bdecc5d78323":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7027bdc0330d43f3a0e7899c45febde7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"43c964640abd4894bcc41673dac1decc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"392633a68c95411699f9949a67bb54d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3aa5131eef043b3b687ec4325ac9287":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3dca09d58d344d3abcea29b748b675f7","IPY_MODEL_cc6c919d82b1437bbb0e10fb19b4bd5c","IPY_MODEL_30c902e667494c8593a710cc96e61c70"],"layout":"IPY_MODEL_c487b86622564c28ad132b59a8edea94"}},"3dca09d58d344d3abcea29b748b675f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4fc43c8595d42618bc6b06bb5c476c7","placeholder":"​","style":"IPY_MODEL_59547ea8e5674a9ba741b8838f2fc8a9","value":"Steps: 200000, archer: 2.07, knight: 0.17: 100%"}},"cc6c919d82b1437bbb0e10fb19b4bd5c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4df2b728625411fa371834d9222fa39","max":200000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ebd74b40f384c028cef294d855735bc","value":200000}},"30c902e667494c8593a710cc96e61c70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a93aa2397e84b46b56e23a84dcde344","placeholder":"​","style":"IPY_MODEL_64279c2218794be38fd0f2ca557f484c","value":" 200000/200000 [32:44&lt;00:00, 101.99it/s]"}},"c487b86622564c28ad132b59a8edea94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4fc43c8595d42618bc6b06bb5c476c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59547ea8e5674a9ba741b8838f2fc8a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4df2b728625411fa371834d9222fa39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ebd74b40f384c028cef294d855735bc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a93aa2397e84b46b56e23a84dcde344":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64279c2218794be38fd0f2ca557f484c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["### Hyperparameter Tuning in RL/MARL\n","\n","Tuning your hyperparameters are very important in RL, as even small tweaks can cause a huge difference in the performance of the policy, especially in a more stochastic environment like MARL.\n","\n","In this tutorial, we will go through how we can tune the hyperparameters, and also use tools like Optuna to tune our hyperparameters more effectively.\n","\n","We'll set up a simple MARL environment, as we did in Unit 2, and tune the hyperparameters"],"metadata":{"id":"Abfimsyo5o3Z"}},{"cell_type":"markdown","source":["### Dependencies"],"metadata":{"id":"RG8oNi8etwxl"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QrdypOPiatwV","executionInfo":{"status":"ok","timestamp":1746510167108,"user_tz":-480,"elapsed":242711,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}},"outputId":"00bb8873-1f65-4582-85f8-16f1a663c3b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchrl==0.7.0\n","  Downloading torchrl-0.7.0-cp311-cp311-manylinux1_x86_64.whl.metadata (39 kB)\n","Collecting torch>=2.6.0 (from torchrl==0.7.0)\n","  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchrl==0.7.0) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchrl==0.7.0) (24.2)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from torchrl==0.7.0) (3.1.1)\n","Collecting tensordict>=0.7.0 (from torchrl==0.7.0)\n","  Downloading tensordict-0.8.2-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n","Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from tensordict>=0.7.0->torchrl==0.7.0) (8.6.1)\n","Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict>=0.7.0->torchrl==0.7.0) (3.10.15)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (4.12.2)\n","Collecting sympy>=1.13.3 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n","Collecting nvidia-nccl-cu12==2.26.2 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n","Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n","Collecting triton==3.3.0 (from torch>=2.6.0->torchrl==0.7.0)\n","  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch>=2.6.0->torchrl==0.7.0) (75.1.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.6.0->torchrl==0.7.0) (1.3.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->tensordict>=0.7.0->torchrl==0.7.0) (3.21.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.6.0->torchrl==0.7.0) (3.0.2)\n","Downloading torchrl-0.7.0-cp311-cp311-manylinux1_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensordict-0.8.2-cp311-cp311-manylinux_2_28_x86_64.whl (414 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m414.3/414.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, tensordict, torchrl\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.1.0\n","    Uninstalling triton-3.1.0:\n","      Successfully uninstalled triton-3.1.0\n","  Attempting uninstall: sympy\n","    Found existing installation: sympy 1.13.1\n","    Uninstalling sympy-1.13.1:\n","      Successfully uninstalled sympy-1.13.1\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.4.127\n","    Uninstalling nvidia-nvtx-cu12-12.4.127:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.21.5\n","    Uninstalling nvidia-nccl-cu12-2.21.5:\n","      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cu124\n","    Uninstalling torch-2.5.1+cu124:\n","      Successfully uninstalled torch-2.5.1+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.7.0 which is incompatible.\n","fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.7.0 which is incompatible.\n","torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 tensordict-0.8.2 torch-2.7.0 torchrl-0.7.0 triton-3.3.0\n","Collecting tensordict==0.7.2\n","  Downloading tensordict-0.7.2-cp311-cp311-manylinux1_x86_64.whl.metadata (9.1 kB)\n","Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from tensordict==0.7.2) (2.7.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensordict==0.7.2) (1.26.4)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from tensordict==0.7.2) (3.1.1)\n","Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict==0.7.2) (3.10.15)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensordict==0.7.2) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (4.12.2)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (1.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (9.5.1.17)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (0.6.3)\n","Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (2.26.2)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (1.11.1.6)\n","Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->tensordict==0.7.2) (3.3.0)\n","Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch>=2.6.0->tensordict==0.7.2) (75.1.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.6.0->tensordict==0.7.2) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.6.0->tensordict==0.7.2) (3.0.2)\n","Downloading tensordict-0.7.2-cp311-cp311-manylinux1_x86_64.whl (400 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tensordict\n","  Attempting uninstall: tensordict\n","    Found existing installation: tensordict 0.8.2\n","    Uninstalling tensordict-0.8.2:\n","      Successfully uninstalled tensordict-0.8.2\n","Successfully installed tensordict-0.7.2\n","Collecting pettingzoo\n","  Downloading pettingzoo-1.25.0-py3-none-any.whl.metadata (8.9 kB)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo) (1.26.4)\n","Requirement already satisfied: gymnasium>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pettingzoo) (1.1.0)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->pettingzoo) (3.1.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->pettingzoo) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->pettingzoo) (0.0.4)\n","Downloading pettingzoo-1.25.0-py3-none-any.whl (852 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m852.5/852.5 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pettingzoo\n","Successfully installed pettingzoo-1.25.0\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Collecting optuna\n","  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n","Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.10 alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n"]}],"source":["!pip3 install torchrl==0.7.0\n","!pip3 install tensordict==0.7.2\n","!pip3 install pettingzoo\n","!pip3 install tqdm\n","!pip3 install optuna"]},{"cell_type":"code","source":["# Torch\n","import torch\n","import torch.nn as nn\n","\n","# Tensordict modules\n","from tensordict.nn import set_composite_lp_aggregate, TensorDictModule, TensorDictSequential\n","from tensordict import  TensorDictBase\n","from torch import multiprocessing\n","\n","# Data collection\n","from torchrl.collectors import SyncDataCollector\n","from torch.distributions import Categorical\n","from torchrl.data.replay_buffers import ReplayBuffer\n","from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n","from torchrl.data.replay_buffers.storages import LazyTensorStorage\n","\n","#Optuna\n","import optuna\n","\n","#Env\n","from torchrl.envs import RewardSum, TransformedEnv, PettingZooWrapper, Compose, DoubleToFloat, StepCounter, ParallelEnv, EnvCreator, ExplorationType, set_exploration_type\n","\n","# Utils\n","from torchrl.envs.utils import check_env_specs\n","\n","# Multi-agent network\n","from torchrl.modules import MultiAgentMLP, ProbabilisticActor, TanhNormal\n","\n","# Loss\n","from torchrl.objectives import ClipPPOLoss, ValueEstimators\n","\n","# Utils\n","torch.manual_seed(0)\n","from matplotlib import pyplot as plt\n","from tqdm.notebook import tqdm"],"metadata":{"id":"UAEUW8Lm75bH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746510181512,"user_tz":-480,"elapsed":14402,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}},"outputId":"19bc5ceb-3433-4584-f252-de5a9ecc5dcc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchrl/data/replay_buffers/samplers.py:37: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. This is likely due to a discrepancy between your package version and the PyTorch version. Make sure both are compatible. Usually, torchrl majors follow the pytorch majors within a few days around the release. For instance, TorchRL 0.5 requires PyTorch 2.4.0, and TorchRL 0.6 requires PyTorch 2.5.0.\n","  warnings.warn(EXTENSION_WARNING)\n"]}]},{"cell_type":"markdown","source":["### Setup Environment"],"metadata":{"id":"PcEXum5rt0Jk"}},{"cell_type":"code","source":["from pettingzoo.butterfly import knights_archers_zombies_v10\n","\n","base_env = knights_archers_zombies_v10.parallel_env(render_mode=\"rgb_array\")\n","env = PettingZooWrapper(base_env)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_j4eaUUk78Om","executionInfo":{"status":"ok","timestamp":1746510182467,"user_tz":-480,"elapsed":954,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}},"outputId":"a5b36929-44bb-42fd-9e80-434e17f61b6c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n","  from pkg_resources import resource_stream, resource_exists\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.11/dist-packages/torchrl/envs/libs/pettingzoo.py:284: UserWarning: PettingZoo in TorchRL is tested using version == 1.24.3 , If you are using a different version and are experiencing compatibility issues,please raise an issue in the TorchRL github.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["### Create a dictionary of default hyperparameters\n","These are the original hyperparameters we will use for the baseline, and we will see if other tuned hyperparameters can lead to better results.\n","\n","Do note that unless you have a powerful computer, you should not touch n_parallel_envs"],"metadata":{"id":"qjD0OLjPt2-K"}},{"cell_type":"code","source":["is_fork = multiprocessing.get_start_method() == \"fork\"\n","device = (\n","    torch.device(0)\n","    if torch.cuda.is_available() and not is_fork\n","    else torch.device(\"cpu\")\n",")\n","\n","#Parameters for Env\n","# Optuna should not be in control of how many envs you run\n","# Unless you want to brick your computer\n","n_parallel_envs = 2  # Number of parallel environments\n","\n","# Default hyperparameters dictionary\n","default_params = {\n","\n","    # Sampling parameters\n","    \"frames_per_batch\": 2000,  # Number of frames collected per training iteration\n","    \"total_frames\": 200000,  # Total frames for training\n","\n","    # Training parameters\n","    \"num_epochs\": 5,  # Number of optimization steps per training iteration\n","    \"minibatch_size\": 400,  # Size of the mini-batches in each optimization step\n","    \"lr\": 3e-4,  # Learning rate\n","    \"max_grad_norm\": 1.0,  # Maximum norm for the gradients\n","\n","    # PPO parameters\n","    \"clip_epsilon\": 0.2,  # Clip value for PPO loss\n","    \"gamma\": 0.99,  # Discount factor\n","    \"lambda\": 0.9,  # Lambda for generalized advantage estimation\n","    \"entropy_eps\": 1e-4,  # Coefficient of the entropy term in the PPO loss\n","\n","    # Network parameters\n","    \"network_depth\": 2,  # Depth of the neural networks\n","    \"network_width\": 256,  # Width of the neural networks\n","    \"activation\": \"Tanh\",  # Activation function\n","    \"share_parameters_policy\": True,  # Whether to share parameters in policy\n","    \"share_parameters_critic\": True,  # Whether to share parameters in critic\n","    \"mappo\": True,  # Whether to use MAPPO (True) or IPPO (False)\n","}\n","\n","# disable log-prob aggregation\n","set_composite_lp_aggregate(False).set()"],"metadata":{"id":"T591cciPD_iE","executionInfo":{"status":"ok","timestamp":1746510182478,"user_tz":-480,"elapsed":7,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### Setting up the transformed environment"],"metadata":{"id":"wI8Jgx9yuNLo"}},{"cell_type":"code","source":["# Create reward transforms with the correct nested tuple keys\n","reward_transforms = [\n","    # For archer agents\n","    RewardSum(\n","        in_keys=[(\"archer\", \"reward\")],  # Use tuple format for nested keys\n","        out_keys=[(\"archer\", \"episode_reward\")]\n","    ),\n","    # For knight agents\n","    RewardSum(\n","        in_keys=[(\"knight\", \"reward\")],  # Use tuple format for nested keys\n","        out_keys=[(\"knight\", \"episode_reward\")]\n","    )\n","]\n","\n","# Apply the transforms\n","make_env = EnvCreator(lambda: TransformedEnv(\n","    PettingZooWrapper(knights_archers_zombies_v10.parallel_env(render_mode=\"rgb_array\")),\n","    Compose(RewardSum(\n","        in_keys=[(\"archer\", \"reward\")],  # Use tuple format for nested keys\n","        out_keys=[(\"archer\", \"episode_reward\")]\n","    ),\n","    # For knight agents\n","    RewardSum(\n","        in_keys=[(\"knight\", \"reward\")],  # Use tuple format for nested keys\n","        out_keys=[(\"knight\", \"episode_reward\")]\n","    ), DoubleToFloat(), StepCounter())\n",")\n",")\n","\n","env = ParallelEnv(n_parallel_envs, make_env, serial_for_single=True)"],"metadata":{"id":"QZzaIXjDEBRp","executionInfo":{"status":"ok","timestamp":1746510182672,"user_tz":-480,"elapsed":188,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["### Check validity of environment"],"metadata":{"id":"h9yCABJcuQSp"}},{"cell_type":"code","source":["print(\"action_keys:\", env.action_keys)\n","print(\"reward_keys:\", env.reward_keys)\n","print(\"done_keys:\", env.done_keys)\n","\n","print(\"Action Spec:\", env.action_spec)\n","print(\"Observation Spec:\", env.observation_spec)\n","print(\"Reward Spec:\", env.reward_spec)\n","print(\"Done Spec:\", env.done_spec)\n","\n","check_env_specs(env)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9SSNlKPED49","executionInfo":{"status":"ok","timestamp":1746510197217,"user_tz":-480,"elapsed":14540,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}},"outputId":"6cde372f-4415-4e7c-bffb-bf270618e96e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["action_keys: [('archer', 'action'), ('knight', 'action')]\n","reward_keys: [('archer', 'reward'), ('knight', 'reward')]\n","done_keys: ['done', 'terminated', 'truncated', ('archer', 'done'), ('archer', 'terminated'), ('archer', 'truncated'), ('knight', 'done'), ('knight', 'terminated'), ('knight', 'truncated')]\n","Action Spec: Composite(\n","    archer: Composite(\n","        action: Categorical(\n","            shape=torch.Size([2, 2]),\n","            space=CategoricalBox(n=6),\n","            device=cpu,\n","            dtype=torch.int64,\n","            domain=discrete),\n","        device=cpu,\n","        shape=torch.Size([2, 2])),\n","    knight: Composite(\n","        action: Categorical(\n","            shape=torch.Size([2, 2]),\n","            space=CategoricalBox(n=6),\n","            device=cpu,\n","            dtype=torch.int64,\n","            domain=discrete),\n","        device=cpu,\n","        shape=torch.Size([2, 2])),\n","    device=cpu,\n","    shape=torch.Size([2]))\n","Observation Spec: Composite(\n","    archer: Composite(\n","        observation: BoundedContinuous(\n","            shape=torch.Size([2, 2, 27, 5]),\n","            space=ContinuousBox(\n","                low=Tensor(shape=torch.Size([2, 2, 27, 5]), device=cpu, dtype=torch.float32, contiguous=True),\n","                high=Tensor(shape=torch.Size([2, 2, 27, 5]), device=cpu, dtype=torch.float32, contiguous=True)),\n","            device=cpu,\n","            dtype=torch.float32,\n","            domain=continuous),\n","        episode_reward: UnboundedContinuous(\n","            shape=torch.Size([2, 2, 1]),\n","            space=ContinuousBox(\n","                low=Tensor(shape=torch.Size([2, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n","                high=Tensor(shape=torch.Size([2, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n","            device=cpu,\n","            dtype=torch.float32,\n","            domain=continuous),\n","        device=cpu,\n","        shape=torch.Size([2, 2])),\n","    knight: Composite(\n","        observation: BoundedContinuous(\n","            shape=torch.Size([2, 2, 27, 5]),\n","            space=ContinuousBox(\n","                low=Tensor(shape=torch.Size([2, 2, 27, 5]), device=cpu, dtype=torch.float32, contiguous=True),\n","                high=Tensor(shape=torch.Size([2, 2, 27, 5]), device=cpu, dtype=torch.float32, contiguous=True)),\n","            device=cpu,\n","            dtype=torch.float32,\n","            domain=continuous),\n","        episode_reward: UnboundedContinuous(\n","            shape=torch.Size([2, 2, 1]),\n","            space=ContinuousBox(\n","                low=Tensor(shape=torch.Size([2, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n","                high=Tensor(shape=torch.Size([2, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n","            device=cpu,\n","            dtype=torch.float32,\n","            domain=continuous),\n","        device=cpu,\n","        shape=torch.Size([2, 2])),\n","    step_count: BoundedDiscrete(\n","        shape=torch.Size([2, 1]),\n","        space=ContinuousBox(\n","            low=Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.int64, contiguous=True),\n","            high=Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.int64, contiguous=True)),\n","        device=cpu,\n","        dtype=torch.int64,\n","        domain=discrete),\n","    device=cpu,\n","    shape=torch.Size([2]))\n","Reward Spec: Composite(\n","    archer: Composite(\n","        reward: UnboundedContinuous(\n","            shape=torch.Size([2, 2, 1]),\n","            space=ContinuousBox(\n","                low=Tensor(shape=torch.Size([2, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n","                high=Tensor(shape=torch.Size([2, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n","            device=cpu,\n","            dtype=torch.float32,\n","            domain=continuous),\n","        device=cpu,\n","        shape=torch.Size([2, 2])),\n","    knight: Composite(\n","        reward: UnboundedContinuous(\n","            shape=torch.Size([2, 2, 1]),\n","            space=ContinuousBox(\n","                low=Tensor(shape=torch.Size([2, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n","                high=Tensor(shape=torch.Size([2, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n","            device=cpu,\n","            dtype=torch.float32,\n","            domain=continuous),\n","        device=cpu,\n","        shape=torch.Size([2, 2])),\n","    device=cpu,\n","    shape=torch.Size([2]))\n","Done Spec: Composite(\n","    done: Categorical(\n","        shape=torch.Size([2, 1]),\n","        space=CategoricalBox(n=2),\n","        device=cpu,\n","        dtype=torch.bool,\n","        domain=discrete),\n","    terminated: Categorical(\n","        shape=torch.Size([2, 1]),\n","        space=CategoricalBox(n=2),\n","        device=cpu,\n","        dtype=torch.bool,\n","        domain=discrete),\n","    truncated: Categorical(\n","        shape=torch.Size([2, 1]),\n","        space=CategoricalBox(n=2),\n","        device=cpu,\n","        dtype=torch.bool,\n","        domain=discrete),\n","    archer: Composite(\n","        done: Categorical(\n","            shape=torch.Size([2, 2, 1]),\n","            space=CategoricalBox(n=2),\n","            device=cpu,\n","            dtype=torch.bool,\n","            domain=discrete),\n","        terminated: Categorical(\n","            shape=torch.Size([2, 2, 1]),\n","            space=CategoricalBox(n=2),\n","            device=cpu,\n","            dtype=torch.bool,\n","            domain=discrete),\n","        truncated: Categorical(\n","            shape=torch.Size([2, 2, 1]),\n","            space=CategoricalBox(n=2),\n","            device=cpu,\n","            dtype=torch.bool,\n","            domain=discrete),\n","        device=cpu,\n","        shape=torch.Size([2, 2])),\n","    knight: Composite(\n","        done: Categorical(\n","            shape=torch.Size([2, 2, 1]),\n","            space=CategoricalBox(n=2),\n","            device=cpu,\n","            dtype=torch.bool,\n","            domain=discrete),\n","        terminated: Categorical(\n","            shape=torch.Size([2, 2, 1]),\n","            space=CategoricalBox(n=2),\n","            device=cpu,\n","            dtype=torch.bool,\n","            domain=discrete),\n","        truncated: Categorical(\n","            shape=torch.Size([2, 2, 1]),\n","            space=CategoricalBox(n=2),\n","            device=cpu,\n","            dtype=torch.bool,\n","            domain=discrete),\n","        device=cpu,\n","        shape=torch.Size([2, 2])),\n","    device=cpu,\n","    shape=torch.Size([2]))\n"]},{"output_type":"stream","name":"stderr","text":["2025-05-06 05:43:17,053 [torchrl][INFO] check_env_specs succeeded!\n"]}]},{"cell_type":"code","source":["n_rollout_steps = 5\n","rollout = env.rollout(n_rollout_steps)\n","print(f\"rollout of {n_rollout_steps} steps:\", rollout)\n","print(\"Shape of the rollout TensorDict:\", rollout.batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HZrEEuTPEFld","executionInfo":{"status":"ok","timestamp":1746510197339,"user_tz":-480,"elapsed":125,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}},"outputId":"030b155c-9c31-4662-e65d-d982874702d4"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["rollout of 5 steps: TensorDict(\n","    fields={\n","        archer: TensorDict(\n","            fields={\n","                action: Tensor(shape=torch.Size([2, 5, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n","                done: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n","                episode_reward: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n","                observation: Tensor(shape=torch.Size([2, 5, 2, 27, 5]), device=cpu, dtype=torch.float32, is_shared=False),\n","                terminated: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n","                truncated: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n","            batch_size=torch.Size([2, 5, 2]),\n","            device=None,\n","            is_shared=False),\n","        done: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n","        knight: TensorDict(\n","            fields={\n","                action: Tensor(shape=torch.Size([2, 5, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n","                done: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n","                episode_reward: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n","                observation: Tensor(shape=torch.Size([2, 5, 2, 27, 5]), device=cpu, dtype=torch.float32, is_shared=False),\n","                terminated: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n","                truncated: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n","            batch_size=torch.Size([2, 5, 2]),\n","            device=None,\n","            is_shared=False),\n","        next: TensorDict(\n","            fields={\n","                archer: TensorDict(\n","                    fields={\n","                        done: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n","                        episode_reward: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n","                        observation: Tensor(shape=torch.Size([2, 5, 2, 27, 5]), device=cpu, dtype=torch.float32, is_shared=False),\n","                        reward: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n","                        terminated: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n","                        truncated: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n","                    batch_size=torch.Size([2, 5, 2]),\n","                    device=None,\n","                    is_shared=False),\n","                done: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n","                knight: TensorDict(\n","                    fields={\n","                        done: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n","                        episode_reward: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n","                        observation: Tensor(shape=torch.Size([2, 5, 2, 27, 5]), device=cpu, dtype=torch.float32, is_shared=False),\n","                        reward: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n","                        terminated: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n","                        truncated: Tensor(shape=torch.Size([2, 5, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n","                    batch_size=torch.Size([2, 5, 2]),\n","                    device=None,\n","                    is_shared=False),\n","                step_count: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n","                terminated: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n","                truncated: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n","            batch_size=torch.Size([2, 5]),\n","            device=None,\n","            is_shared=False),\n","        step_count: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n","        terminated: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n","        truncated: Tensor(shape=torch.Size([2, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n","    batch_size=torch.Size([2, 5]),\n","    device=None,\n","    is_shared=False)\n","Shape of the rollout TensorDict: torch.Size([2, 5])\n"]}]},{"cell_type":"markdown","source":["### Dump all the model architecture and training code into functions\n","\n","As much as it hurts my eyes as it hurts yours, Optuna requires us to spawn a fresh environment and model each time we train, so we have to gather all of the previously separated notebook cells into a single function\n","\n","This is especially so if the architecture depends on the hyperparameters Optuna suggests to it\n","\n","However, for our FlattenObs and process_batch helper utilities, they do not require any hyperparameters, so we can abstract them out of the functions"],"metadata":{"id":"WPBpXAekuYll"}},{"cell_type":"code","source":["n_archers = env.observation_spec[\"archer\", \"observation\"].shape[1]\n","n_knights = env.observation_spec[\"knight\", \"observation\"].shape[1]\n","n_entities = env.observation_spec[\"archer\", \"observation\"].shape[2]\n","n_features = env.observation_spec[\"archer\", \"observation\"].shape[3]\n","\n","# Create a flattening module that handles the batched_env+time dimensions\n","class FlattenObs(nn.Module):\n","    def forward(self, obs):\n","        # Convert to float first\n","        obs = obs.float()\n","\n","        # Handle different possible shapes\n","        if len(obs.shape) == 5:  # [batch_env, time, n_agents, n_entities, n_features]\n","            batch_env, time, n_agents, n_entities, n_features = obs.shape\n","\n","            # Reshape to merge batch_env and time dimensions\n","            # This gives [batch_env*time, n_agents, n_entities, n_features]\n","            obs = obs.reshape(-1, n_agents, n_entities, n_features)\n","\n","            # Take only the first entity for each agent (agent itself)\n","            return obs[:, :, 0, :]  # [batch_env*time, n_agents, n_features]\n","\n","        elif len(obs.shape) == 4:  # [batch, n_agents, n_entities, n_features]\n","            batch, n_agents, n_entities, n_features = obs.shape\n","            return obs[:, :, 0, :]  # [batch, n_agents, n_features]\n","\n","        elif len(obs.shape) == 3:  # [batch, n_entities, n_features]\n","              batch, n_entities, n_features = obs.shape\n","              return obs.reshape(batch, n_entities * n_features)\n","\n","        # Fallback for unexpected shapes\n","        return obs\n","\n"],"metadata":{"id":"BVQ1oCnEEHrC","executionInfo":{"status":"ok","timestamp":1746510197355,"user_tz":-480,"elapsed":14,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["groups = [\"archer\", \"knight\"]\n","\n","def process_batch(batch: TensorDictBase) -> TensorDictBase:\n","    \"\"\"\n","    Expand done and terminated keys for each group to match reward shape.\n","    \"\"\"\n","    for group in groups:  # Changed from env.group_map.keys()\n","        keys = list(batch.keys(True, True))\n","        group_shape = batch.get_item_shape(group)\n","        nested_done_key = (\"next\", group, \"done\")\n","        nested_terminated_key = (\"next\", group, \"terminated\")\n","        if nested_done_key not in keys:\n","            batch.set(\n","                nested_done_key,\n","                batch.get((\"next\", \"done\")).unsqueeze(-1).expand((*group_shape, 1)),\n","            )\n","        if nested_terminated_key not in keys:\n","            batch.set(\n","                nested_terminated_key,\n","                batch.get((\"next\", \"terminated\"))\n","                .unsqueeze(-1)\n","                .expand((*group_shape, 1)),\n","            )\n","    return batch"],"metadata":{"id":"KPxp8JVyceys","executionInfo":{"status":"ok","timestamp":1746510197379,"user_tz":-480,"elapsed":23,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# 100 LOC dump of all model code, because you need to have everything wrapped in\n","# an objective function for Optuna to optimise\n","def setup_models(params, env, device):\n","    \"\"\"\n","    Set up policy and critic models using parameter dictionary.\n","\n","    Args:\n","        params: Dictionary of hyperparameters\n","        env: Environment instance\n","        device: Computing device\n","\n","    Returns:\n","        tuple: (policies, critics) dictionaries\n","    \"\"\"\n","    n_archers = env.observation_spec[\"archer\", \"observation\"].shape[1]\n","    n_knights = env.observation_spec[\"knight\", \"observation\"].shape[1]\n","    n_entities = env.observation_spec[\"archer\", \"observation\"].shape[2]\n","    n_features = env.observation_spec[\"archer\", \"observation\"].shape[3]\n","\n","    # Create activation function\n","    if params[\"activation\"] == \"Tanh\":\n","        activation_class = torch.nn.Tanh\n","    elif params[\"activation\"] == \"ReLU\":\n","        activation_class = torch.nn.ReLU\n","    else:\n","        activation_class = torch.nn.Tanh  # Default\n","\n","    # Create policy modules for each agent type\n","    policy_modules = {}\n","    for group in [\"archer\", \"knight\"]:\n","        n_agents = n_archers if group == \"archer\" else n_knights\n","        share_parameters_policy = params[\"share_parameters_policy\"]\n","\n","        # Create MLP for policy\n","        policy_mlp = MultiAgentMLP(\n","            n_agent_inputs=n_features,  # Only using features of the agent itself\n","            n_agent_outputs=6,  # 6 discrete actions in KAZ\n","            n_agents=n_agents, # 2 agents per type\n","            centralised=False, #The agents are decentralised\n","            share_params=share_parameters_policy,\n","            device=device,\n","            depth=params[\"network_depth\"],\n","            num_cells=params[\"network_width\"],\n","            activation_class=activation_class,\n","        )\n","\n","        # Create sequential module with flattening\n","        policy_seq = nn.Sequential(FlattenObs(), policy_mlp, nn.Softmax(dim=-1))\n","\n","        # Wrap in TensorDictModule\n","        policy_modules[group] = TensorDictModule(\n","            module=policy_seq,\n","            in_keys=[(group, \"observation\")],\n","            out_keys=[(group, \"probs\")]\n","        )\n","\n","    # Create actors for each agent type\n","    policies = {}\n","    for group in [\"archer\", \"knight\"]:\n","        policies[group] = ProbabilisticActor(\n","            module=policy_modules[group],  # Use the policy module directly\n","            spec=env.action_spec[group, \"action\"],\n","            in_keys=[(group, \"probs\")],\n","            out_keys=[(group, \"action\")],\n","            distribution_class=Categorical,\n","            return_log_prob=True,\n","        )\n","\n","    agents_policy = TensorDictSequential(*policies.values())\n","\n","\n","    # Create critics\n","    critics = {}\n","    for group in [\"archer\", \"knight\"]:\n","        n_agents = n_archers if group == \"archer\" else n_knights\n","        share_parameters_critic = params[\"share_parameters_critic\"]\n","        MAPPO = params[\"mappo\"]\n","\n","        # Wrap flattener in TensorDictModule\n","        flatten_obs_module = TensorDictModule(\n","            FlattenObs(),\n","            in_keys=[(group, \"observation\")],\n","            out_keys=[(group, \"flat_observation\")],\n","        )\n","\n","        # Create critic module\n","        critic_module = TensorDictModule(\n","           module = MultiAgentMLP(\n","               n_agent_inputs=n_features,\n","               n_agent_outputs=1,\n","               n_agents=n_agents,\n","               centralised=MAPPO, #True for MAPPO, False for IPPO\n","               share_params=share_parameters_critic,\n","               device=device,\n","               activation_class=activation_class,\n","               depth=params[\"network_depth\"],\n","               num_cells=params[\"network_width\"],\n","           ), in_keys = [(group, \"flat_observation\")], out_keys = [(group, \"state_value\")]\n","        )\n","\n","        # Combine modules\n","        critics[group] = TensorDictSequential(\n","            flatten_obs_module,\n","            critic_module,\n","        )\n","\n","    return policies, agents_policy, critics"],"metadata":{"id":"mzu_FX67EIQJ","executionInfo":{"status":"ok","timestamp":1746510197600,"user_tz":-480,"elapsed":217,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def train_model(env, params, policies, agents_policy, critics, device):\n","    \"\"\"\n","    Train the model using the specified parameters, policies, and critics.\n","\n","    Args:\n","        env: Environment\n","        params: Dictionary of hyperparameters\n","        policies: Dictionary of policy modules\n","        critics: Dictionary of critic modules\n","        device: Computing device\n","\n","    Returns:\n","        float: Mean reward achieved during training\n","    \"\"\"\n","    # Create data collector\n","    collector = SyncDataCollector(\n","        ParallelEnv(n_parallel_envs, make_env),\n","        policy=agents_policy,\n","        frames_per_batch=params[\"frames_per_batch\"],\n","        total_frames=params[\"total_frames\"],\n","        device=device,\n","        storing_device=device,\n","    )\n","\n","    # Create loss modules for each agent type\n","    loss_modules = {}\n","    for group in [\"archer\", \"knight\"]:\n","        loss_modules[group] = ClipPPOLoss(\n","            actor=policies[group],\n","            critic=critics[group],\n","            clip_epsilon=params[\"clip_epsilon\"],\n","        )\n","\n","        loss_modules[group].set_keys(\n","            reward=(group, \"reward\"),\n","            action=(group, \"action\"),\n","            value=(group, \"state_value\"),\n","            done=(group, \"done\"),\n","            terminated=(group, \"terminated\")\n","        )\n","\n","        loss_modules[group].make_value_estimator(ValueEstimators.GAE, gamma = params['gamma'], lmbda = params[\"lambda\"])\n","\n","    # Create optimizers\n","    optimizers = {}\n","    for group in [\"archer\", \"knight\"]:\n","        optimizers[group] = torch.optim.Adam(\n","            list(policies[group].parameters()) + list(critics[group].parameters()),\n","            lr=params[\"lr\"],\n","        )\n","\n","    replay_buffers = {}\n","    for group in groups:\n","        # Create storage and buffer\n","        storage = LazyTensorStorage(params[\"frames_per_batch\"])\n","        sampler = SamplerWithoutReplacement()\n","        replay_buffers[group] = ReplayBuffer(\n","            storage=storage,\n","            sampler=sampler,\n","            batch_size = params[\"minibatch_size\"],\n","        )\n","\n","    # Training loop (using the structure from paste.txt)\n","    pbar = tqdm(\n","        total=params[\"total_frames\"],\n","        desc=\", \".join([f\"episode_reward_mean_{group} = 0\" for group in groups])\n","    )\n","    episode_reward_mean_map = {group: [] for group in groups}\n","    total_frames_so_far = 0\n","\n","    # Training/collection iterations\n","    for iteration, batch in enumerate(collector):\n","        batch = process_batch(batch)  # Expand done keys if needed\n","\n","        # Calculate total frames in this batch\n","        current_batch_size = batch.numel()\n","        total_frames_so_far += current_batch_size  # Track total frames\n","\n","        # Process each group\n","        for group in groups:\n","            # Extract data for this group only\n","            group_batch = batch.exclude(\n","                *[\n","                    key\n","                    for _group in groups\n","                    if _group != group\n","                    for key in [_group, (\"next\", _group)]\n","                ]\n","            )\n","\n","            # Reshape to flatten batch dimensions\n","            group_batch = group_batch.reshape(-1)\n","\n","            # Add to this group's replay buffer\n","            replay_buffers[group].extend(group_batch)\n","\n","            # PPO training epochs (multiple passes over the same data)\n","            for _ in range(params[\"num_epochs\"]):\n","                # Iterate through all minibatches in the buffer once\n","                for subdata in replay_buffers[group]:\n","                    # Compute loss\n","                    loss_vals = loss_modules[group](subdata)\n","\n","                    # Compute total loss\n","                    loss_value = (\n","                        loss_vals[\"loss_objective\"] +\n","                        loss_vals[\"loss_critic\"] +\n","                        loss_vals[\"loss_entropy\"]\n","                    )\n","\n","                    # Backprop and optimize\n","                    optimizers[group].zero_grad()\n","                    loss_value.backward()\n","\n","                    # Gradient clipping\n","                    torch.nn.utils.clip_grad_norm_(\n","                        loss_modules[group].parameters(), params[\"max_grad_norm\"]\n","                    )\n","\n","                    optimizers[group].step()\n","\n","        # Update collector policy with new weights\n","        collector.update_policy_weights_()\n","\n","        # Logging with error handling\n","        for group in groups:\n","            done_mask = batch.get((\"next\", group, \"done\"))\n","\n","            # Check if any episodes finished\n","            if done_mask.any():\n","                episode_reward_mean = (\n","                    batch.get((\"next\", group, \"episode_reward\"))[done_mask]\n","                    .mean()\n","                    .item()\n","                )\n","            else:\n","                # No episodes finished, use previous value or 0\n","                episode_reward_mean = (\n","                    episode_reward_mean_map[group][-1] if episode_reward_mean_map[group] else 0.0\n","                )\n","\n","            episode_reward_mean_map[group].append(episode_reward_mean)\n","\n","        # Update description with step count\n","        pbar.set_description(\n","            f\"Steps: {total_frames_so_far}, \" +\n","            \", \".join([\n","                f\"{group}: {episode_reward_mean_map[group][-1]:.2f}\"\n","                for group in groups\n","            ]),\n","            refresh=False\n","        )\n","\n","        # Update progress bar with total frames processed in this batch\n","        pbar.update(current_batch_size)\n","\n","    # Calculate final mean reward (average of last 10 episodes for each group)\n","    final_rewards = {}\n","    for group in groups:\n","        if episode_reward_mean_map[group]:\n","            last_n = min(10, len(episode_reward_mean_map[group]))\n","            final_rewards[group] = sum(episode_reward_mean_map[group][-last_n:]) / last_n\n","        else:\n","            final_rewards[group] = 0.0\n","\n","    # Return average of all group rewards\n","    return sum(final_rewards.values()) / len(final_rewards)\n","\n"],"metadata":{"id":"Slu03v1AEJui","executionInfo":{"status":"ok","timestamp":1746510197613,"user_tz":-480,"elapsed":12,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["### Setting up hyperparameter tuning\n","\n","This is the KEY driving code -  We set up an objective function that creates hyperparameters, and suggests new ones based on constraints set by the user\n","\n","`suggest_<type>` is key here: It allows us to force a certain type like integer, and get Optuna to generate new hyperparameter configurations based on the arguments given."],"metadata":{"id":"QkJb3DEIvEo5"}},{"cell_type":"code","source":["def objective(trial):\n","    \"\"\"\n","    Optuna objective function for hyperparameter optimization.\n","\n","    Args:\n","        trial: Optuna trial object\n","\n","    Returns:\n","        float: Mean reward (metric to maximize)\n","    \"\"\"\n","    # Define hyperparameters to optimize\n","    params = {\n","        # Sampling parameters\n","        \"frames_per_batch\": 2000,  # Fixed for consistency\n","        \"total_frames\": 20000,  # Reduced for faster trials\n","\n","        # Training parameters\n","        \"num_epochs\": trial.suggest_int(\"num_epochs\", 3, 10),\n","        \"minibatch_size\": trial.suggest_categorical(\"minibatch_size\", [200, 400, 800]),\n","        \"lr\": trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True),\n","        \"max_grad_norm\": trial.suggest_float(\"max_grad_norm\", 0.5, 2.0),\n","\n","        # PPO parameters\n","        \"clip_epsilon\": trial.suggest_float(\"clip_epsilon\", 0.1, 0.3),\n","        \"gamma\": trial.suggest_float(\"gamma\", 0.95, 0.999),\n","        \"lambda\": trial.suggest_float(\"lambda\", 0.9, 1.0),\n","        \"entropy_eps\": trial.suggest_float(\"entropy_eps\", 1e-5, 1e-3, log=True),\n","\n","        # Network parameters\n","        \"network_depth\": trial.suggest_int(\"network_depth\", 1, 3),\n","        \"network_width\": trial.suggest_categorical(\"network_width\", [64, 128, 256, 512]),\n","        \"activation\": trial.suggest_categorical(\"activation\", [\"Tanh\", \"ReLU\"]),\n","        \"share_parameters_policy\": True,  # Fixed for simplicity\n","        \"share_parameters_critic\": True,  # Fixed for simplicity\n","        \"mappo\": trial.suggest_categorical(\"mappo\", [True, False]),\n","    }\n","\n","    # Setup device\n","    is_fork = multiprocessing.get_start_method() == \"fork\"\n","    device = torch.device(0) if torch.cuda.is_available() and not is_fork else torch.device(\"cpu\")\n","\n","    # Initialize environment (replace with your actual env)\n","    env = ParallelEnv(n_parallel_envs,make_env)  # This function needs to be defined\n","\n","    # Setup models using parameter dictionary\n","    policies, agents_policy, critics = setup_models(params, env, device)\n","\n","    # Train the model and get mean reward\n","    mean_reward = train_model(env, params, policies, agents_policy, critics, device)\n","    #We report back the mean reward, but you can always use other heuristics like weighted average etc.\n","\n","    return mean_reward\n"],"metadata":{"id":"7LMczV7kYoh8","executionInfo":{"status":"ok","timestamp":1746510197618,"user_tz":-480,"elapsed":1,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["### Using Optuna to tune hyperparameters\n","\n","We then create a study, allowing us to optimize in a given direction and take the best hyperparameters."],"metadata":{"id":"p871rKaMweVs"}},{"cell_type":"code","source":["# This will take very long\n","\n","study = optuna.create_study(direction=\"maximize\")\n","study.optimize(objective, n_trials=2)  # Adjust based on computational resources (n = 2 is very small)\n","\n","# Print best parameters\n","print(\"Best trial:\")\n","trial = study.best_trial\n","print(f\"  Value: {trial.value}\")\n","print(\"  Params:\")\n","for key, value in trial.params.items():\n","    print(f\"    {key}: {value}\")\n","\n","# Save best parameters\n","import json\n","with open(\"best_params.json\", \"w\") as f:\n","    json.dump(trial.params, f, indent=2)\n","\n","# If you want to use the best parameters for a full training run\n","best_params = {\n","\n","    # Sampling parameters (use full budget for final training)\n","    \"frames_per_batch\": 2000,\n","    \"total_frames\": 200000,  # Full training budget\n","\n","    # Other parameters from best trial\n","    \"num_epochs\": study.best_params[\"num_epochs\"],\n","    \"minibatch_size\": study.best_params[\"minibatch_size\"],\n","    \"lr\": study.best_params[\"lr\"],\n","    \"max_grad_norm\": study.best_params[\"max_grad_norm\"],\n","    \"clip_epsilon\": study.best_params[\"clip_epsilon\"],\n","    \"gamma\": study.best_params[\"gamma\"],\n","    \"lambda\": study.best_params[\"lambda\"],\n","    \"entropy_eps\": study.best_params[\"entropy_eps\"],\n","    \"network_depth\": study.best_params[\"network_depth\"],\n","    \"network_width\": study.best_params[\"network_width\"],\n","    \"activation\": study.best_params[\"activation\"],\n","    \"share_parameters_policy\": True,\n","    \"share_parameters_critic\": True,\n","    \"mappo\": study.best_params[\"mappo\"],\n","}\n","\n","# Create environment for final training\n","env = ParallelEnv(n_parallel_envs, make_env)\n","\n","# Setup device\n","is_fork = multiprocessing.get_start_method() == \"fork\"\n","device = torch.device(0) if torch.cuda.is_available() and not is_fork else torch.device(\"cpu\")\n","\n","# Setup models with best parameters\n","policies, agents_policy, critics = setup_models(best_params, env, device)\n","\n","# Final training run\n","print(\"Starting final training with best parameters...\")\n","final_reward = train_model(env, best_params, policies, agents_policy, critics, device)\n","print(f\"Final training complete. Mean reward: {final_reward:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":480,"referenced_widgets":["8e685e9ef862476eb869c38bcf491552","4119a2a26e1943fc8b4148298286adb8","2cab29f57c7342c8bd92d5634c19aea2","f58b4aa33d5f40a2ac9d52dd2a6d530f","103d9eeae2b747d6828834a71db83e41","d35e26a2bb034bef9b3ff380ec4a7cad","3602de3b944d49b9b04cf78d27d57d29","30a347b06fc245c6be38675b7db7bcb5","5c39313d2f1d4f94925e2bbc7f215551","216378eb10d04c078376e85abb9f26b1","e1589ba5a48b4ec586c0ef8502bda37a","04afb5a50e8f418eb9819974455c0ea0","30b2f477f33142f5ba580c2ac28b9fea","5310e81202224daca61255e303564e22","701ff12605fa48108032d9361e4ca26f","a21eed07b208462f8688935f8d4f843d","1c220f50239f4cc1bed16cd9e098e5fa","4fa2804eaeb8497993813d7d7d5572b8","c925342e556c4efab636bdecc5d78323","7027bdc0330d43f3a0e7899c45febde7","43c964640abd4894bcc41673dac1decc","392633a68c95411699f9949a67bb54d4","f3aa5131eef043b3b687ec4325ac9287","3dca09d58d344d3abcea29b748b675f7","cc6c919d82b1437bbb0e10fb19b4bd5c","30c902e667494c8593a710cc96e61c70","c487b86622564c28ad132b59a8edea94","a4fc43c8595d42618bc6b06bb5c476c7","59547ea8e5674a9ba741b8838f2fc8a9","a4df2b728625411fa371834d9222fa39","2ebd74b40f384c028cef294d855735bc","7a93aa2397e84b46b56e23a84dcde344","64279c2218794be38fd0f2ca557f484c"]},"id":"aKz8LZknY9yA","executionInfo":{"status":"ok","timestamp":1746512574636,"user_tz":-480,"elapsed":2377017,"user":{"displayName":"SOC AI SOCIETY","userId":"14965631179156013617"}},"outputId":"39cda411-22f8-44cf-f2fa-f8cb2bfefc39"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["[I 2025-05-06 05:43:17,385] A new study created in memory with name: no-name-869a675e-56cd-4a62-b44f-b8c49d0fff2c\n"]},{"output_type":"display_data","data":{"text/plain":["episode_reward_mean_archer = 0, episode_reward_mean_knight = 0:   0%|          | 0/20000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e685e9ef862476eb869c38bcf491552"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-05-06 05:46:47,811] Trial 0 finished with value: 0.9996051313355565 and parameters: {'num_epochs': 9, 'minibatch_size': 800, 'lr': 7.552929913851593e-05, 'max_grad_norm': 1.9377070642698397, 'clip_epsilon': 0.15359331146445357, 'gamma': 0.9794602657565913, 'lambda': 0.9807239806093849, 'entropy_eps': 0.00011986779432457749, 'network_depth': 1, 'network_width': 128, 'activation': 'Tanh', 'mappo': False}. Best is trial 0 with value: 0.9996051313355565.\n"]},{"output_type":"display_data","data":{"text/plain":["episode_reward_mean_archer = 0, episode_reward_mean_knight = 0:   0%|          | 0/20000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04afb5a50e8f418eb9819974455c0ea0"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[I 2025-05-06 05:50:16,605] Trial 1 finished with value: 0.9937416618689895 and parameters: {'num_epochs': 7, 'minibatch_size': 400, 'lr': 5.41729303067796e-05, 'max_grad_norm': 0.9941180552407667, 'clip_epsilon': 0.1212771008887426, 'gamma': 0.9560376967733367, 'lambda': 0.9725653294185096, 'entropy_eps': 0.0006881180021790127, 'network_depth': 2, 'network_width': 128, 'activation': 'Tanh', 'mappo': False}. Best is trial 0 with value: 0.9996051313355565.\n"]},{"output_type":"stream","name":"stdout","text":["Best trial:\n","  Value: 0.9996051313355565\n","  Params:\n","    num_epochs: 9\n","    minibatch_size: 800\n","    lr: 7.552929913851593e-05\n","    max_grad_norm: 1.9377070642698397\n","    clip_epsilon: 0.15359331146445357\n","    gamma: 0.9794602657565913\n","    lambda: 0.9807239806093849\n","    entropy_eps: 0.00011986779432457749\n","    network_depth: 1\n","    network_width: 128\n","    activation: Tanh\n","    mappo: False\n","Starting final training with best parameters...\n"]},{"output_type":"display_data","data":{"text/plain":["episode_reward_mean_archer = 0, episode_reward_mean_knight = 0:   0%|          | 0/200000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3aa5131eef043b3b687ec4325ac9287"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Final training complete. Mean reward: 0.9924\n"]}]}]}