{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "159bl5Cq3XuT"
   },
   "source": [
    "# End to End Reinforcement Learning (DQN)\n",
    "\n",
    "In this tutorial, you will learn how to train a simple DQN Model using TorchRL. We will explore different optimizaions for a single agent setup, and train a simple agent to complete MountainCar-v0.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3425,
     "status": "ok",
     "timestamp": 1746502856795,
     "user": {
      "displayName": "SOC AI SOCIETY",
      "userId": "14965631179156013617"
     },
     "user_tz": -480
    },
    "id": "_bsAJu2tXLAQ",
    "outputId": "e27a2eb7-b2d2-48b8-ec14-41d4e94dfcc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchrl==0.7.0 in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
      "Requirement already satisfied: gymnasium==0.29 in /usr/local/lib/python3.11/dist-packages (0.29.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
      "Requirement already satisfied: av in /usr/local/lib/python3.11/dist-packages (14.3.0)\n",
      "Requirement already satisfied: tensordict==0.7.2 in /usr/local/lib/python3.11/dist-packages (0.7.2)\n",
      "Requirement already satisfied: torch>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchrl==0.7.0) (2.6.0+cu124)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchrl==0.7.0) (2.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from torchrl==0.7.0) (24.2)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from torchrl==0.7.0) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29) (4.13.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29) (0.0.4)\n",
      "Requirement already satisfied: orjson in /usr/local/lib/python3.11/dist-packages (from tensordict==0.7.2) (3.10.18)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.6.0->torchrl==0.7.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.6.0->torchrl==0.7.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.6.0->torchrl==0.7.0) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchrl==0.7.0 gymnasium==0.29 tqdm matplotlib av tensordict==0.7.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVUb2oYu4Bxx"
   },
   "source": [
    "### Dependencies and Setup\n",
    "\n",
    "The code below imports all libraries needed for TorchRL to work. TorchRL is more modular compared to other libraries, leading us to need to import many different moving parts in order to train an agent. However, the benefit becomes it is much easier to extend our agent and customise it, as opposed to other frameworks like Stable Baseline 3 and Tianshou\n",
    "\n",
    "\n",
    "NOTE: Google Colab prompts for changes whenever the numpy version is changed, so just restart your session and all should be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4612,
     "status": "ok",
     "timestamp": 1746502999858,
     "user": {
      "displayName": "SOC AI SOCIETY",
      "userId": "14965631179156013617"
     },
     "user_tz": -480
    },
    "id": "DJbrKPzfaapD"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import Video\n",
    "import os\n",
    "\n",
    "# https://gymnasium.farama.org/\n",
    "'''DO NOT ACCIDENTALLY INSTALL OPENAI GYM, IT IS OUTDATED'''\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "# Port environment into TorchRL\n",
    "from torchrl.envs import GymWrapper\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from torch import multiprocessing\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from tensordict.nn import TensorDictModule\n",
    "from torch import nn\n",
    "\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
    "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
    "from torchrl.data import OneHot\n",
    "from torchrl.envs import (\n",
    "    Compose, DoubleToFloat,\n",
    "    ObservationNorm, StepCounter,\n",
    "    TransformedEnv\n",
    ")\n",
    "from torchrl.envs.transforms import Transform\n",
    "from torchrl.envs import ParallelEnv, EnvCreator, SerialEnv\n",
    "from torchrl.envs.utils import check_env_specs, ExplorationType, set_exploration_type\n",
    "from torchrl.modules import QValueActor\n",
    "from torchrl.objectives import DQNLoss\n",
    "from tqdm.notebook import tqdm\n",
    "from torchrl.record import VideoRecorder\n",
    "from torchrl.record.loggers import CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFjkSxQ343qJ"
   },
   "source": [
    "### Creating the environment\n",
    "\n",
    "We choose to create the MountainCar-v0 environment, where the goal is to train an agent to reach the top of the right hill.\n",
    "\n",
    "Unlike in the previous tutorial, we set up our environment slightly differently: We are using a lambda object instead of just feeding TransformedEnv directly.\n",
    "\n",
    "We will explore more on why so in later cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1746502999868,
     "user": {
      "displayName": "SOC AI SOCIETY",
      "userId": "14965631179156013617"
     },
     "user_tz": -480
    },
    "id": "yfB-K4fzOl4Q"
   },
   "outputs": [],
   "source": [
    "## Reward Shaping - To ensure we get somewhat better performance (You can tweak this to give better results!)\n",
    "\n",
    "class VelocityPositionReward(Transform):\n",
    "    def __init__(self, velocity_weight=5.0, position_threshold=0.0, side_bonus_weight=2.0, base_reward=0.0):\n",
    "        super().__init__()\n",
    "        self.velocity_weight = velocity_weight\n",
    "        self.side_bonus_weight = side_bonus_weight\n",
    "        self.position_threshold = position_threshold  # Threshold to determine left vs right side\n",
    "        self.base_reward = base_reward\n",
    "        self.max_velocity = None\n",
    "        self.min_velocity = None\n",
    "\n",
    "    def _step(self, tensordict, next_tensordict):\n",
    "        # Extract velocity and position from the next observation\n",
    "        velocity = next_tensordict[\"observation\"][..., 1]\n",
    "        position = next_tensordict[\"observation\"][..., 0]  # Assuming position is at index 0\n",
    "\n",
    "        # Initialize velocity trackers for new episodes if needed\n",
    "        if self.max_velocity is None or self.min_velocity is None or next_tensordict.get(\"done\", False).any():\n",
    "            self.max_velocity = velocity.clone()\n",
    "            self.min_velocity = velocity.clone()\n",
    "\n",
    "        # Update max_velocity when a new maximum is reached\n",
    "        self.max_velocity = torch.maximum(velocity, self.max_velocity)\n",
    "\n",
    "        # Update min_velocity when a new minimum is reached\n",
    "        self.min_velocity = torch.minimum(velocity, self.min_velocity)\n",
    "\n",
    "        # Start with base reward + velocity component (as in original)\n",
    "        reward = self.base_reward + self.velocity_weight * self.max_velocity\n",
    "\n",
    "        # Apply position-based velocity bonus\n",
    "        left_side = position < self.position_threshold\n",
    "        right_side = position >= self.position_threshold\n",
    "\n",
    "        # For left side positions, bonus for negative velocity (going left)\n",
    "        left_bonus = torch.where(\n",
    "            left_side & (velocity < 0),\n",
    "            self.side_bonus_weight * torch.abs(self.min_velocity),\n",
    "            torch.zeros_like(velocity)\n",
    "        )\n",
    "\n",
    "        # For right side positions, bonus for positive velocity (going right)\n",
    "        right_bonus = torch.where(\n",
    "            right_side & (velocity > 0),\n",
    "            self.side_bonus_weight * self.max_velocity,\n",
    "            torch.zeros_like(velocity)\n",
    "        )\n",
    "\n",
    "        # Add the bonuses to the reward\n",
    "        reward = reward + left_bonus + right_bonus\n",
    "\n",
    "        # Update the reward in the next_tensordict\n",
    "        next_tensordict.set(\"reward\", reward.unsqueeze(-1))\n",
    "\n",
    "        return next_tensordict\n",
    "\n",
    "    def _reset(self, tensordict, tensordict_reset):\n",
    "        # Reset the velocity tracking\n",
    "        self.max_velocity = None\n",
    "        self.min_velocity = None\n",
    "        return tensordict_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 366,
     "status": "ok",
     "timestamp": 1746503000237,
     "user": {
      "displayName": "SOC AI SOCIETY",
      "userId": "14965631179156013617"
     },
     "user_tz": -480
    },
    "id": "plSb7Cq4accg",
    "outputId": "ed1e5b3b-e541-4504-8a2a-9340de238e38"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import resource_stream, resource_exists\n",
      "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n",
      "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(pkg)\n"
     ]
    }
   ],
   "source": [
    "HOME_DIR = Path(\"/working\")\n",
    "os.makedirs(HOME_DIR, exist_ok = True)\n",
    "RANDOM_SEED = 42\n",
    "DEVICE = 'cpu'\n",
    "OUTPUT_DIR = Path(\"./working\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "VIDEO_DIR = OUTPUT_DIR / \"my_exp\" / \"videos\"\n",
    "\n",
    "'''\n",
    "How to make an environment in TorchRL\n",
    "\n",
    "env = gym.make(\"MountainCar-v0\", render_mode = \"rgb_array\")\n",
    "base_env = GymWrapper(env, device = DEVICE, categorical_action_encoding=False) #Change this to false as we use OneHot\n",
    "'''\n",
    "\n",
    "logger = CSVLogger(exp_name=\"my_exp\", log_dir = OUTPUT_DIR, video_format=\"mp4\")\n",
    "\n",
    "# 1) Factory for the recording env (worker 0)\n",
    "def make_nonrecording_env():\n",
    "    base = GymWrapper(\n",
    "        gym.make(\"MountainCar-v0\"),\n",
    "        device=\"cpu\",\n",
    "        categorical_action_encoding=False\n",
    "    )\n",
    "    return TransformedEnv(\n",
    "        base,\n",
    "        Compose(\n",
    "            DoubleToFloat(),\n",
    "            VelocityPositionReward(),\n",
    "            StepCounter(),\n",
    "\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "#Build a **serial** env with the recorder\n",
    "base = GymWrapper(\n",
    "    gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\"),\n",
    "    device=DEVICE,\n",
    "    categorical_action_encoding=False,\n",
    "    from_pixels=True,\n",
    "    pixels_only=False,\n",
    ")\n",
    "rec_env = TransformedEnv(\n",
    "    base,\n",
    "    Compose(\n",
    "        DoubleToFloat(),\n",
    "        VideoRecorder(logger, tag=\"only_video\", skip=5),\n",
    "        VelocityPositionReward(),\n",
    "        StepCounter(),\n",
    "\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwwcYbXT5mtA"
   },
   "source": [
    "### Hyperparameters\n",
    "\n",
    "These values change the complexity of the neurual network and other variables when training, such as batch size, total number of frames per episode,  replay buffer batches etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1746503000239,
     "user": {
      "displayName": "SOC AI SOCIETY",
      "userId": "14965631179156013617"
     },
     "user_tz": -480
    },
    "id": "CYmiDbWMawd_"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Optimization Hyperparameters\n",
    "\n",
    "num_cells = 64  # number of cells in each hidden layer\n",
    "lr = 3e-4\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "# Collection Hyperparams\n",
    "\n",
    "# How many frames to simulate the environment with the current policy\n",
    "# before you start optimizing your policy\n",
    "frames_per_batch = 2000\n",
    "\n",
    "# After this number of frames, stop training.\n",
    "# For serious training endeavors, do at least 1M steps.\n",
    "total_frames = 250_000\n",
    "\n",
    "# Algorithm Hyperparameters\n",
    "\n",
    "# In Supervised Learning, this is your Batch Size.\n",
    "# Here we are referring to a small slice of the frames we collected above.\n",
    "# This is passed wholesale into the policy for backpropagation.\n",
    "sub_batch_size = 64\n",
    "\n",
    "# How many times you want to loop through the collected frames\n",
    "# during your optimization phase.\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztfN2OU270gZ"
   },
   "source": [
    "### Parallel Environments\n",
    "\n",
    "If you had run the previous code for testing in Unit 1.1, the code would have taken a very long time to train a baseline PPO model. That is because simulating the agent on the environment is very compute intensive. By trading off memory usage, we can create multiple environments in parallel to speed up training.\n",
    "\n",
    "To do this, we call ParallelEnv, and feed it a lambda that creates a new environment. We also provide the number of environments we would like to provide in parallel.\n",
    "\n",
    "Due to constraints in the Colab instance provided, we have reduced the number of parallel environments to 2. Do feel free to try and optimise the code to allow for larger parallel runs if you are interested!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16904,
     "status": "ok",
     "timestamp": 1746503018003,
     "user": {
      "displayName": "SOC AI SOCIETY",
      "userId": "14965631179156013617"
     },
     "user_tz": -480
    },
    "id": "WGuiNu2yayIi",
    "outputId": "a4c815be-6b5e-4f1e-ac5b-e2f2ccfcafdd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 03:43:37,851 [torchrl][INFO] check_env_specs succeeded!\n",
      "2025-05-06 03:43:37,965 [torchrl][INFO] check_env_specs succeeded!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "composed_env = ParallelEnv(3, make_nonrecording_env) #Parallel env makes it faster\n",
    "\n",
    "''' print(\"observation_spec:\", composed_env.observation_spec)\n",
    "print(\"reward_spec:\", composed_env.reward_spec)\n",
    "print(\"input_spec:\", composed_env.input_spec)\n",
    "print(\"action_spec (as defined by input_spec):\", composed_env.action_spec)\n",
    "\n",
    "assert composed_env.batch_size == (2,) '''\n",
    "\n",
    "check_env_specs(composed_env)\n",
    "check_env_specs(rec_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGFyXyE28-ea"
   },
   "source": [
    "### Q Learning\n",
    "Over here we set up a simple Q Learning pipeline to learn how to solve MountainCar-v0.\n",
    "\n",
    "The Q Learning Pipeline can be summed into\n",
    "1. Create the value module.\n",
    "1. Create a QValueActor using the value module\n",
    "\n",
    "\n",
    "\n",
    "We use LazyLinear, which is an abstraction on nn.Linear, but it ignores the input shape, allowing us to focus on the architecture rather than also focus on ensuring the tensor shapes fit at every step of the implementation.\n",
    "\n",
    "This will culminate in us eventually having to solve the shape errors if any during the training loop/rollouts with the policy, but saves us a lot of time and mental energy from dealing with the other moving parts in RL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1746503022434,
     "user": {
      "displayName": "SOC AI SOCIETY",
      "userId": "14965631179156013617"
     },
     "user_tz": -480
    },
    "id": "qS9k-0TIa1OJ"
   },
   "outputs": [],
   "source": [
    "# Simple DQN Setup\n",
    "\n",
    "# You can skip these if you want, these are the underlying neural networks.\n",
    "# Since we are using a Discrete policy, we need to use a OneHot to show that we are giving a discrete action\n",
    "\n",
    "value_net = nn.Sequential(\n",
    "    nn.LazyLinear(num_cells, device=DEVICE),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(num_cells, device=DEVICE),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(num_cells, device=DEVICE),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(composed_env.action_spec.shape[-1], device=DEVICE),\n",
    ")\n",
    "\n",
    "spec = OneHot(composed_env.action_spec.shape[-1])\n",
    "\n",
    "# Critic Module\n",
    "value_module = QValueActor(\n",
    "    module=value_net,\n",
    "    in_keys=[\"observation\"],\n",
    "    spec = spec\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2760,
     "status": "ok",
     "timestamp": 1746503025983,
     "user": {
      "displayName": "SOC AI SOCIETY",
      "userId": "14965631179156013617"
     },
     "user_tz": -480
    },
    "id": "AXlXfafYa0Hr",
    "outputId": "c7f58415-aae0-496e-840b-4140a2c56e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        step_count: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([3]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([3, 3]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        action_value: Tensor(shape=torch.Size([3, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        chosen_action_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([3, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        step_count: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([3]),\n",
      "    device=cpu,\n",
      "    is_shared=False)\n",
      "tensor([[1, 0, 0],\n",
      "        [0, 0, 1],\n",
      "        [0, 1, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        action_value: Tensor(shape=torch.Size([200, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        chosen_action_value: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                done: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                observation: Tensor(shape=torch.Size([200, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                pixels: Tensor(shape=torch.Size([200, 400, 600, 3]), device=cpu, dtype=torch.uint8, is_shared=False),\n",
       "                reward: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                step_count: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([200]),\n",
       "            device=cpu,\n",
       "            is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([200, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        pixels: Tensor(shape=torch.Size([200, 400, 600, 3]), device=cpu, dtype=torch.uint8, is_shared=False),\n",
       "        step_count: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        truncated: Tensor(shape=torch.Size([200, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([200]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's some code that shows how you can shape-check your TensorDicts.\n",
    "\n",
    "# Source TensorDict\n",
    "td = composed_env.reset()\n",
    "print(td)\n",
    "\n",
    "# You should notice, at least for this problem, that we have 3 new keys: `action`, `logits`, `sample_log_prob`\n",
    "# By doing so, TorchRL allows you to examine each step of your rollout pipeline.\n",
    "# Shape Check: done.\n",
    "print(value_module(td))\n",
    "\n",
    "# Compare and contrast to a random action generated by the environment's specs.\n",
    "print(composed_env.rand_step()['action'])\n",
    "\n",
    "# Do a final rollout to make sure the collection process works end-to-end.\n",
    "composed_env.rollout(3, value_module)\n",
    "\n",
    "#Roll out on the recording env to record videos\n",
    "rec_env.rollout(30000, value_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ju3lu1hZj16"
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "executionInfo": {
     "elapsed": 2140,
     "status": "ok",
     "timestamp": 1746503028125,
     "user": {
      "displayName": "SOC AI SOCIETY",
      "userId": "14965631179156013617"
     },
     "user_tz": -480
    },
    "id": "hyIddof0eW5x",
    "outputId": "9c25c860-21ca-4a46-8a97-29687f7abcc4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video controls  >\n",
       " <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAALH5tZGF0AAACqQYF//+l3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2NSAtIEguMjY0L01QRUctNCBBVkMgY29kZWMgLSBDb3B5bGVmdCAyMDAzLTIwMjUgLSBodHRwOi8vd3d3LnZpZGVvbGFuLm9yZy94MjY0Lmh0bWwgLSBvcHRpb25zOiBjYWJhYz0xIHJlZj0zIGRlYmxvY2s9MTowOjAgYW5hbHlzZT0weDM6MHgxMTMgbWU9aGV4IHN1Ym1lPTcgcHN5PTEgcHN5X3JkPTEuMDA6MC4wMCBtaXhlZF9yZWY9MSBtZV9yYW5nZT0xNiBjaHJvbWFfbWU9MSB0cmVsbGlzPTEgOHg4ZGN0PTEgY3FtPTAgZGVhZHpvbmU9MjEsMTEgZmFzdF9wc2tpcD0xIGNocm9tYV9xcF9vZmZzZXQ9LTIgdGhyZWFkcz0yIGxvb2thaGVhZF90aHJlYWRzPTIgc2xpY2VkX3RocmVhZHM9MSBzbGljZXM9MiBucj0wIGRlY2ltYXRlPTEgaW50ZXJsYWNlZD0wIGJsdXJheV9jb21wYXQ9MCBjb25zdHJhaW5lZF9pbnRyYT0wIGJmcmFtZXM9MyBiX3B5cmFtaWQ9MiBiX2FkYXB0PTEgYl9iaWFzPTAgZGlyZWN0PTEgd2VpZ2h0Yj0xIG9wZW5fZ29wPTAgd2VpZ2h0cD0yIGtleWludD0yNTAga2V5aW50X21pbj0yNSBzY2VuZWN1dD00MCBpbnRyYV9yZWZyZXNoPTAgcmNfbG9va2FoZWFkPTQwIHJjPWNyZiBtYnRyZWU9MSBjcmY9MjMuMCBxY29tcD0wLjYwIHFwbWluPTAgcXBtYXg9NjkgcXBzdGVwPTQgaXBfcmF0aW89MS40MCBhcT0xOjEuMDAAgAAABbpliIQAMv/+9uy+BTX9n9CXESzF2kpwPiqkgIB3NMAAAAMAAAMAABYJ9COw5KoDd0AAALdn+k88/SIAJtqYIpPDxaFPXqOsP8EYeZ8Hoq1BUxOYmAAC5vaDA+SbDBv2D3tG5J46Y4hOfHlcfZpSNfMR6KiCXXbkD2IaYiO57rEs3TNM/YskrMb4WUpsx/4DlK0vhp/U+9tQgRt1GD1eWMOK+/VoF8WEaQJU6HTYk3t5RC+7tqXj0mfKexSvFnZlO629Mja1BRZjj7BEeAD14EABY6KwiQ5oAJp9YUX2+2JdQt8WHhRJzcL4OO5mACGE+fBrHUDaUHRPbhANCININ5ZPyQ+uNXhsIOkJgTi6sPHgGCqwXS3cUZWPh2JR3SkMDB68HF5aXRRc8fLh7fTF/Q34TXk6ItnkWjWZxLUaCQHhJ1j2EndqzCQcYsAOOZOE47HSRCJxzRUrv0Lo4KrAMluw00QaiEIlZPrkeA3Ke1JGsGNd2fwKRAeCsyLC+tsqbQiaQ1vyvE7l93d3Pfj8ucSXkj0URCiakMNExYQ1oeuPmXRC6d3UhzUKVey60FNBit9qlJmf4hK3b3n8Iy7SeKWxJuvXDY0+tgJsaS6wV3cCsZHPT4jJdDPDhr0XCaaN8ZHIKfgM8FG+6Sixhg2J4P/EkWKniT7SZPIJwq1brzNaqvSRBMZEb3DS9z96eGRMnocSA3IW96YKh7OG+0jPK6VovwCPpjsaIOKEPXAQ7HYPDHIQNIeIRVon0wFV6tn1hKiOq6HaZySGIrrTElU8TEntML2ucX50PvUajrFTP7LaVJgMIhFHXsjL7AH4UensPfWfI7spd/xDd6hoGzY6vmsMtWlGsutNqh2JiL3TT7QNtPrpzYoHlgbgyakuF92jNHYCAATr5ifFngnlQu3i9oAAAAMAAXntVCFGIv3RSedwC8lsECJ+6iKbUYIX+1B2nLAdVXKg/B04Au8vaHLaghe/f5vdNdfZOcMiKRGK/yzyfrTyQD/vAUEXdBAOA0dtzM841k0PVmyztM9vJzH6FAslAALxsYEA5om2N96zQ3AHccsXrwzd/5VYK3HKYAtpcOuaq20aXohJjWw3NaSvg1n9QkQAB37LGl67oZJiziAZ3ri5wdTv4n8YfwVUEDU5kNKKD9u0baC5f2/I0D2whsyPhUWOm+X+2TrSuQceKrTnv9IHBSxrGKlbbzFP3J3+lS/gRcve9LMMYRY7dtNAHB8oU2uwwqkRdXhhT4RvuIp5xwJbtD6SCf3CV3MxU/3PPb6rm6nCRWLJ5H0Hzxop0/osGlzq6hHzfz5N8pyAmBcYHXfytv36EjHlSnIZq3MUtWFZ+S/nJeTLNlrZ9J5QQB6MvYEe598Mf75dXsb+BQYz0uLOYuXVFpRAPTZQGkmQ/ZAXXYE9sNV6DNIyCCD0csYme/FwB8AGh4CEV7frthfCB1KjpdxG7391cU8ZN8XCHhG1eqK730pi4otRcPSbnt481HfnU8Cze6D91Fr1GgVfErf2wEVE3Onaarjh8zrWF3r9eAOuRaHF75E9ksyAms2Ten5WQiE2DyDDnM+HFEMuS54xjj8B48bi27Zn5r3EeY4MHRhPdhfmjgdqXxO30V/IEYAX8fc0Bl3NQPaHSP0udAniG22+TFGirwZfB0Rtc+7zl6tII1o7ad5A4+tVHcXJBuMKg3VAPykgDGc5N7X2yV5lS9V0Vu3NAsm+U7iudW3Eyikf4wlNTlW/5LEMABXma/ZR62dXNqFie7OfQZo6GiM9G9WQpJemii8cvKkww1QHoS4nQLjeY0RdkghWI/iKND7A7DANgSthIkuqmkQaYUst3wMcEwV1LsVRWAjX/oe/TBgAQ5IpbxctdynZbH5OVbREzsy6soaYsIZY93ce7uYSn9YSywk1ZyTJ/w9Gc54tv/2FRrXMp9Tav5gOCtFNV4i9V1UNn4DtgQAACA1lAPeIhAAy//727L4FNf2f0GV58JUfwAwGA0AYLEY495b2B8ShubF+4K9d9ojuZ3/02qhDJ1I2vniabCeqDIUIGWLAEJm2LQ9TjBM9/a9MFLSkHldz061f9paVsnPF2Pf9Dx8jbf925FIT6vx2O26j1qKY2QDbdCruAA76eRyUKQ51eFnbZXWQiqG20ZY4tc+jfYljwYiNdyM4368mH/KZYN7WLNtk14msmRckwHBX9kUu6I7e0DN+Xh7fIDvT7wEiSIlBFcAAAsipbm7q4zyTa/qBzBVGxSfdE9wFPljGcTtVKNt5R+zeS04NMonxYYz+Mt9OUSjo63nVe/sR1gc/v7YcncmGilUwiX7AhDrtdwCIwBte+5RQqWJTy0hIWVs7kmc/Fc9ET/1tcgAAJkOK/YbObeXrGQDueqIi14kWXxMA0JaCR8dKHyQjGuFI8pwlKDhOsA83LkXrUmGmlaQABac0IoIN6VWfcFNgYZMGJnIY/kpRt1KnHGTBYFRd4AAJiwK5CversVjF2dkSfU95z95wZXRKrYan2JY1nNmi59U9thAarrsRLCFzuAv+NKDDtKOgzig2nuJ6ADClilJENBqMtAuS1pARVDrdya9fUD5CYTLTv1whzUMa5Kj2lk19tWOI5U74dZUdlaHAA17+nKUrgSyUIhdaEDIz2Eu+QoU+atTI9cvLqgV+a0uWLvfjv/ANq4AOSu1UFCfK+fIT/l4dWTF0CpfmmRbAZoFU/ZjthfJE+jgZw8tBRYHJeWE5Owgv5aebdzRX3qIOoFtPtozHECFhhnlyfptO2IcljAmcn0/TvVDcko1SSUnyxzm/yAlNvSjqTb9TiTwjtecAd7X/iAPG9bB/nyh/qdoITse4MJJgQPoTZXW2sPe2Uillp7PMIE7Q4U4h/DYZkNgBDsAnfcpa7PVxctoz8Zz/udozkWxIHIVBvp5LZCw8D4rVspfJlbK//vVbEugmjTklxjw62Ne2D5Z52iOF+LCCUns/vuOWAgsJEakET/Ojrjc6dBQQ1V5NO/+NhCMDQe+HEpBiE8SkR3na9Q1vWwg5vlVvw61lPhpTF9MeRZYmwyHnmakToEOGmBRTVHWD3H4PRLtALHq5m2LK8GJIxAHxmpBhJHtvP43+h9IhFc6AIGcMc8ATWSibHcTB4s57sKXW1W/9hawu0L312mfGMb37NVkGh698IaatcOLieWhDK6Hcu9WMghS9X0ujevalnJ9TGpDcAL7aYkNVOhonocsk9UaxBMSubeBqC9QahdrRkxowv0dpyCDJy2JO2J/Q2jxGdtDcsbThKMXv+V+01cCfnGA7DbAAHRji5O0RD5TUASPSvFPAygj5lwg57XSOIBgnJlCITD9Im8zbph0LXmHgiWsMrwYkTzUdlOmLr93Qdo/w04Mu2696icRdOrwT3anKECO5oa+r9NwcefroVeMMML4BrUJ9Z2nBaytrHdCZvyqs6+/L/dp+9iBKGguxjpoDbBWzIaB0ghfEk5clztpbohRnTwRXcFHyezNnQkv3ABv44uR4XTdr1YyQnk040eGPx/c3SdIBqSpRRWrnp9Im8zM5f+NlshECj2uh0kIfGv1igqWbTsp6D1g22P8CeZBxKY7Vb2C/RkVvvusK6KdXceXXPYf4Ty6lifLVLzX5GNPKUlMpA12k9BoUqGFobgjOhUnul+/nVEnv1dYZ/x5P+gr1v21iCpR00qGQNOW5xBtYdZllmxEjSSV191aRpdXSjLkJzQTLZgWxRWjK8EOfiC8IxbOBFydbjLxqLKZS/uKWpbaijhn8vVNLpno7UbcetIza/dqPgYUKKcDBroAB3b89uyBh48+7QN4LuOaX6D2C9EjvZ7DaOrKLbrUxeefGgwjw7wzc8yT0GtiE+LmbI5ysXsZg+6oW/tqNfY+NlFeF4qtXoCxHhiz7ir5REc54L1VL2kHzNyiMBs/QiXJLRMKBmkVnwJYcAwNju5k3cZv9kNp7QjgOnf8Sa1mXDQy/Z8hjra2mNtsV5eOC4rs03Y2rydIRMXQSKmolvQrBjJEJb1cW189PkrI33iKhOUKFHjyDuXsSyQaRpPLkq2GIvy/z2OO4pzqnLEXjmvD8e8JjGZQICA2hvzNEN4RJnzsW+FvEbHqtbtbzW+gNwc5ntnF+6ftMNRrIqt0Ayd4jtBg5yRVgcjTyxI578TWoOdzPlVSs0K06YlrKIVd2Pu+Xii2zsUfFHeaecV26cJXhuN1XFJI768o+O3wYTGHQSpR45M9haEVQMR//N1B2XmGKH6NUU1qv0uXkAAZPfQ4YAMqpecVsVN+JdSWfBlh4xGwgzaYhsSFX5hCXNYhjHFiWHbs5ncP/7VAf42gAzAnsxHuu8u5CQWE1RiLp3fe7yGC1CGVl23ZVlxhwnxyHg3MeQuQJ/7jWqgQJYwqXVvggFZc05hOaJGKyoFhdvyZcxvSMX5WLO5H2f56ZgiBq2JV2gF7vVUHWdUJBgBlmYA8F2A5iWzEOaYq13TH/ZkjiT1fXV+eJgFTsxDJR/Tr7EhcoN6vJ7utKa4n9nsxRI1M2SqzoH1A7cH/n0+sEnepmN99XuU2c2fg9cg7wjr4gZftVpPC9zxoxwKYZ9zkufYqbwxb3LTivaQKGsBYrwNDwEM+5286FeHuYLCHZSa2eb2ttrFINtu3QYp2PmaOqsr/yOhMyTBdAw6KeHAhDNAx+EKO7mgGoJcCsUrNofxu5W1P/lgAl9t81EZMIAHbAuIEAAAA1QZoibEMv/p4QAAnv1oAKOZjtI/4ErW40sYjyhJWdcimpReAKDH5dV78ZXDelCcZ75i0OWmsAAAFXQQD3miJsQy/+nhAYs/OAPS7SwpHL+LdBqxjK4kL2SjjXWM5z9aaYWrtO5+5QP4r7JbUYIKppUBfz8QNe/u5quMHuSqC/zkt+fPZ8P4SSRK1o5RaT9vUt2iGkqPCXZAmq7URvjPR4mH6A9YONy+5MIn0wzKRTbWNauOrf9RLzHpuvLkSM7UkDvTZO6ULo+sGhxllklTv1mf9H5kNtkabGm0fVTRULBS+L+y3WpleXqIHHIrtDYCxc5pNNIWVp4AOSar4wSIIkyU+MI/CCjijCoJN0wbYVCzpyeICmIq9LT9cpJz+thsylqjrSby8UXH0Mwk6nqyfyTFkXdHQRv4D9womO94DEmJqxr0WaT2u/brbbcxRK+nlskX2jg/4xw6wyrr+lfeyUYlUZ1P+1mUaUTiFzrlsPrKWXjg2NeD5M0Low6b2Ao20zIIdnra815Asa8WbrrluagAAAAA0BnkF5Cb8AArLMvH+BAAAAbAEA955BeQm/AKHK0IkTcHtlowR9/IHMxaNWwIwZgqE/XODCX4msqSlJtfx2UAAZwcLZueJEAH2XTwjECmb8kA0+LVe4RPYq7StEzWU1LHd1i8tF10xnxT1+ExBtNqD51/0EqoT43ZZ00Kr5gQAAABFBmkM8IZMphDL//p4QAAAGBAAAALZBAPeaQzwhkymEMv/+nhAABbPd+V+1DmFUyYfKCkV0+AEHHl/G1ZkkAEljFcPuQqduyQXOjHneXMcADqfC7tq4g1/xN8ZFmo/aNhEo/ueLPDD49vlcr3Tt17t9iuc0p2JUa/LDovMIDWK5IlrrJuGsdI6hdlCBN7kFYzhYfWq82rzCqm5miELz0/QfWMQ3hFQx/2f2ShL4k1M0qDub1mi+KFT3cQ4eBySpimRKW2m2JWYbbLPOQQAAABNBmmRJ4Q8mUwIbf/6nhAAAAwGLAAAAxkEA95pkSeEPJlMCG3/+p4QAAJMmnPESVBuADHjYpLDOTjC9k+o+qjusVFoMhsE5hA7dfKqM3QbEdlIDYTY+xnhq/hd6CMZYK90yhgUxoBNLxHMtPhm3BGH9JT/zr4wi1aE9MSuNLCOWaGn4ncPWHfL8CMP7r+fTJlHkQ9e7ap2J3DPjysUHOnoC6MtovjQooakfPxUicS4C8/wbSNsVmtyqX0LDF2O8ElrzXLDuRewWN1G86mj84FvFyg5OP8gqwnCtxKz4sQAAABVBmoZJ4Q8mUwURPDb//qeEAAADAYsAAAEMQQD3moZJ4Q8mUwURPDb//qeEAAGIAWSYOYeojhAAQ+3rQUmUW9O2iho9JW4FsLgPb5WcIQMF5FUShL7X930cm7e4Mwl9y9GvZM2Z76+V5wF2d9oPvUQTC9SO3tF2NDuV3HL8jg8atY3NwXTAswonl9Nai1M0dgNUu2edMExpn5Piodzg72zB8YUMkcTrtOTpZGH+TrkudHPumwk2zffI+gBFw/R/CSsyTc8GcqLyNQUJdlhS6vZnkZEf+Fggaas9i33PmdbvD02QzGPgts/vZ1gzz97KNSqf9bPN+lQX7BqWRniY3kO7fOI5Jh0TiR2Y/PTGndBhxEnpQ5+1DMQoTpuOm7usN+g6uslxUQAAAAsBnqVqQm8AAAMBnwAAAGUBAPeepWpCbwChytCBn06qtG6iwSBsNeN1uQfSRZbyzZ1pCEv/r9DiPTixxABqIPJhY8s0eRGXKSn070B2FmkTGSDGS2yPzIZwh3DoxXlCkRWBUjO3AgmK9DjQe2aKXPO4ifSW8QAAABJBmqpJ4Q8mUwIZf/6eEAAABgUAAACHQQD3mqpJ4Q8mUwIZf/6eEAAF9n7Us+QAc4EGL6CZ9uWh/YdxOBZAhvlVd0URdvpV9Cr6AWpS0HGjnnK0GfhVrGx6IC7lxysaQLb4Bitl+TFFoN4CF/pyMvL+I1H1Zdaa+fjQtL542X5oxkuzL1UYDKsvihzmQLj/tdhgEEfb6XU38o/7Rd9RAAAADUGeyEURPCr/AAADAUEAAAB1QQD3nshFETwq/wB7FHNCoZpPw3h0Guw6vwK0AVysHRqZrYtBvA0q2d4M97sYTJ5w1w314kLTmtEjLyMGIKiZUdVJVAnZCi55EkqBDHUV8nYHabQ5e0Dd/4CpEeiFyZ1AAP76fjMnQ9zdGFD3z/i7OhyVt2BsAAAACwGe53RCbwAAAwGfAAAAawEA957ndEJvAAGbRbUS4r0TUzqeWBXbOi6aLhz+u0uQkGSZFwADsW5ZGtgw9wSPL+mow+c/j21BO3L6cMQ0L7QFibXMFBb+BdsHmtYdZDBJriXbpvrTzQ9z0FSw3ZUfB6AQUiriH/t0Q0eoAAAACwGe6WpCbwAAAwGfAAAAYAEA957pakJvAAGalbFZ4auEr1qPV6ul2b7nAxgquHSY8MIRuxaTWtL5U6phh8U5EAIQSwigOZFvQHvRpSSmCb3KJVf5tr4jDD+S5L5FLWob8Ak6GWohosdenklvxtNdaQAAABNBmutJqEFomUwIZf/+nhAAAAYEAAAAr0EA95rrSahBaJlMCGX//p4QAAX/hOj0TOUMvtMZ8tpAASeL8Na9tTYGOpg9t8RZGsc9iMBc9fWzG6XDrtY+QIDePmElN0z865LM2X1HWYy102VS1A1RHST7wBbrEj3M22f2ohunDRBm+kHPPQ89gYQibZtXY5dja4KgVKtLW7FvABSn3U8A4rBIsPkk9YbEeIiOnVW43yF4N6qieLlsmNCifcGdFieZQvXPWx6INSEAAAAUQZsNSeEKUmUwURLDL/6eEAAABgQAAAEqQQD3mw1J4QpSZTBREsMv/p4QAAWtvEsgAIwNG5jfyaqcm1PWfR2JaI6f9IQ1roL4rNFVzbd2nSbXWvJ+gD5wRjq1Qy019nsrFth5+u+947ucrlkat0ndVmmCt+vnMzjtKKiVQt//aU4xa2mpQ5WHHLC5KaoFSgT/xeo4RrYZCJXxsfSyvfDXI2aXImnojQZot6UEgg2wGJjyaJtKTfQLCwm82xTyyd4C/Pl8EgJdOSHGBjIuM5yhoH6YAP0AUF99CCMpI6nEYAQSX/ctYkElJleSNlXCEsaJvsACAuAwT0MegdrJnfIr78BNNKq3j0Az5JU2W9BMclwG7ePClZv0C5W3ZPOe7lNKuBBRCxK39UhKQ1jRP3imDGa2o1mrAnSbCgZUsJObuf59RwAAAAsBnyxqQm8AAAMBnwAAAHEBAPefLGpCbwChytCBds4QB0fFekoo7K/uHSn96tCUY9R4y5CYqIVBB3WA1Vjxy+8sJXTnk09qtHYvr4C4rzaNCEjhLjH20LilR4x9Bhuc3KiiuNKaBLUBB5fwjl4SaGY4fm9Z10VPRGb2RPf4qW/BLwAAABJBmzBJ4Q6JlMCF3/6MsAAABg0AAAB7QQD3mzBJ4Q6JlMCF3/6MsAAFtsI9I87eD+c+effIfXEAHUia4FRWaBdn6/QdxvEWrCm4w/BC+GG6UFl1NQS9iAuaBqk1f6XaQPEPUbGt1mWtmVcRJs5R7JyXFbZ54NlH4CxRMvt++StKMgJ6I0F3VrOCdecdX8Dng+Z1AAAADUGfTkUVPCr/AAADAUEAAABiQQD3n05FFTwq/wB7FHNCfPv2h+s1rjuMNfLmTOylt0WaxlV1IDPIrJBrhAB7u59DdQPxwFRpODBKOJw7bmM+glfwDc+5PcRl+X/nr4Q2Afwh7iNBHvbqtQc1nkVYPgeUF/0AAAALAZ9vakJvAAADAZ8AAAAyAQD3n29qQm8AAYfvnxWyllZ/cw1tKblEugABDc8O7hYbebjSg2P5GM+GrmbM0X9qBRAAAAATQZtxSahBaJlMCF3//oywAAAGDAAAALpBAPebcUmoQWiZTAhd//6MsAAFtaILUx2ukQALZ6mr7cu1M0n4BR5vZZUI6OKK70M3VObkFwGv3NEaE+6/fn9U6Jepe6YnhnpPhhjvz399cSWAjB3Cjl+xU6Z1IKOZ7jZhNfNpKPEIRer0QzKNN8leeMQWuuk/E8DjxcQpDlC75TZoXJcU/hAbW4mFMHAeuWJhxrrdsPRzmgaJN17KJk8i0Yudcz6h81g50Np5VX2D1yoGwE9nq7ru6ZwAAAATQZuSSeEKUmUwIZf//p4QAAAGBQAAAKxBAPebkknhClJlMCGX//6eEAAFs936wbI0k8LglctwAiD13ESPQC3wLMLOBiSqraXSTa7L3j284Yh4mFHlEMvR1MM9V99JjKyd9OTXoBCTWISdQGHZ5uihZPMGlcXTQfLOcbn9VNJRASIna/ut8hdCdCdJyz+MWz2eJQ5rY9xmE2PUXzIbAl/SD2F1D9HqYHyFU1dzvo4W1f/pMSfdlkVDff2aYEjLR84YOcqxAAAAEkGbs0nhDomUwIZf/p4QAAAGBAAAAOVBAPebs0nhDomUwIZf/p4QAAX1d6tLIADoGkNzDrDcE7A/1j3DjnVvAhEkJdeYE//tqHbN96VmjWavViepKkcV5l9OhxzRbOp0L3XeTcsmfqAb34ermqqUdik0j2jRmiAINe7Rjo0MfS4Szeu0LWQYfPXHpgKaL1z6k0BJmDPw00+U+9YvIg4bcrdVmrqITZIGPq+oG9UVSYx5c4MooIAkxtGOLGOxz7x8T0lCUMhn1vTCeJk4P2bmDJ4NSFMmXMEGVd1Q3XdR/0VzPCga3NE7+9dd/cK+LF7SiudUdaCsudPtUGTAAAAAEkGb1EnhDyZTAhl//p4QAAAGBAAAANhBAPeb1EnhDyZTAhl//p4QAAX1df1U4AF04dTylVuPkbfy7HKOiI5K8qVLQiFWAi5Od2XtYP6+bwdvl/YsDHjrlrsFh9g9/btD4nwOrSoczHeleTOCLAy0dNT6qjLSV6VRvZpkA36P57RQyi9xC4Zj6O1WdxWj288J105krRgnynvpYZXw28M27ItM54ccTMgQ4KEp72w66BtRbvKixalX/hky1EmGI0rjzK36WvnZ6bUl/V+pCwFK0H8AJv3HcqnfsF8Ol+4rwW6L4cVIvjgUxgA0fc+4kTAAAAATQZv1SeEPJlMCG3/+p4QAAAMBiwAAALZBAPeb9UnhDyZTAht//qeEAAGIAo7mqlV/AAIapJgHhAhv9ABzx+z1krba/i5CyS5SXPB6A3DeSXB2P10hD/tLmgI+uI94Bxe1wGClyJcMxbANaXq2f9E7E6j5Fie8u12wXttDsSx7z6fNG3pVXeXcFsl8TPP4h8czeD/I+Vop6R6lwCfiopTjaJ8kAtlhpQ941pNEeyizxRveAzHQn5+TFTjfG/7u/yw3+D//PfplxAacVgSzTQAAABJBmhlJ4Q8mUwIZf/6eEAAABgQAAACwQQD3mhlJ4Q8mUwIZf/6eEAAF/9judNC1loEz/O2GNMEAIP38SzQm7ji14zYnPzWqSmImzhMgBOi+vh7dPaDJLg9r18tT3AvV5/XbBCiKeDdXbo3UhtmIsrpY+aBesdsB4+uaVeWTr5wqZYozcQIUazh8wvNA71fiZrCVaU0JMrlbzPDw+0Fgl0fKAMgX3wwK1Q0GtZJCneUU9SKNlR1F0TMDVymEQtjYykA2LP/gPIEAAAANQZ43RRE8Kv8AAAMBQQAAAGpBAPeeN0URPCr/AHsUc0Kz6OvOoztAagaEe20M4oj8TiPXKYY1ACE5FQ0sdJPnX7R9tzdFH0p0AwOvyxhoblxs+Gpx5/xyOb+lTArKwREvmgmhD/ST/cp4gC+OXs30u0vdHf/+Pgf6gizBAAAACwGeVnRCbwAAAwGfAAAASQEA955WdEJvAAGl8Bs5nDLsN0trw+7t5sAV/stlU55k9DVxdtF0TRQAP3VYojIk6avCGwCnWVg0eSJ+YGuZ+pZK5UfhsyBI5lkAAAALAZ5YakJvAAADAZ8AAAB8AQD3nlhqQm8AAaZ3j2IpiZksrxItFdptzUqE7JA7I5KFDfhyD19IpDHqfIOtV7gx1UoAG1ClsNugij3ot3sUKqPywovNhtdJaE+j7EdY5Zz7YJiShutbA9uIH+2/STWj69yl0mia5RNJlHLnHNz5A45ytOrPacQtXIcrgAAAABNBmlpJqEFomUwIZf/+nhAAAAYFAAAAxEEA95paSahBaJlMCGX//p4QAAWzffweFEwC1nrQoRzzNxkibV44l9XnW7MIae65UpQcElR3belbbWSQKDQFjTUg3i4fY+ovMi8aTbacZ9XdYNwo34pEoxGvOr4SEJGC40a4tdojO3l37A2HMrGiA1V6iRglMFbZZfx8+mnSZKhgLh+jppxoh9XDCup9FuPaSH2kCfBiP8n35pILJjeL8r3pMQlRZPfRGXveN44oKm0qhR1dU6dh5lCRfYQZovTDhdIV+MEAAAATQZp+SeEKUmUwIXf//oywAAAGDAAAAPNBAPeafknhClJlMCF3//6MsAAFtmI3AEQ6cSk96ZKO+/leZvu080VsDQFT7osq5VEVllbiU9hDFGk4iSBTGB7Ylt5dgx+ZbJukQzzOavpKliMbRvTGiOR/oQSZ2Wvmf/yaq69pa3Ab7txywac3KcuxDr6pinTaP+iWU8byjj4P0+hrlxFAsSOg/kxR/TP9B2PV9LsdcQb8Se70ckFmIfm7YvSjSNPSUjCR3vjib29el2Yg5IAceYUUMCFTdLjlMJeJKKwv2DF0YY6YY7sGLFZIhRRC7XZ5CGkl/yEfFKK5CJ0wymaXtm9uXyq8q399a/7HTGAAAAANQZ6cRTRMKv8AAAMBQQAAAFVBAPeenEU0TCr/AHxjdfivW+sfW3GkA1K4BAAIfkUEYRRl2pZOCuZ3buXocJHbrVCslgR/J0eCdPYLNz9rBJ74wFZBmYbRPYO1X3oLfHwvTiT+EHSJAAAACwGeu3RCbwAAAwGfAAAAUwEA9567dEJvAAGl9Hi4BPHupMcOrON0uRH2m6PcJxuaLJD0Nv/PXg2EXD314oOTKACHOEn6KqboSq6+KxsOQeXKOLHTkc72ihq6hgZWAVRJJpKZAAAACwGevWpCbwAAAwGfAAAAXAEA9569akJvAAGmebfGXCXKuTDjZyLt52cznycv1cutgsi4UCV9ibnRi2ACcnIJ/FGSzhz/m/wC3ns7Q6JdUvPBq8HUEWY+wQUH+Lu7D5gxptaCFes67R7+aH4EAAAAE0Gav0moQWiZTAhl//6eEAAABgQAAACaQQD3mr9JqEFomUwIZf/+nhAABawVce0AAnbOJEgWWDszJYi/NKgkOYoNQDnaMmtmi6DPPdFY+dt5J2XfbDXb3+xa51MgnHcY4cTVCePKIAciuVHmOMTpsNO7rKTFPy+v9ixO7vKNtOR+zw6u8FAcWxUlaAYCu/6oJT/32bNJfJPmcqX9+au0MSZYcGpzVKoRAH5laLBnynsmaAAAABNBmsBJ4QpSZTAhl//+nhAAAAYFAAAAj0EA95rASeEKUmUwIZf//p4QAAWqtslfdxmPqFo4bPU3sqkwAQ1UjHeCXBd79ZZ8jjZmnovnaCUj7Hn+5mnr1DwbGrdDOAK1Zrt8w3p9SnI3kFSGL/kS/I/1HvUptCWypKbCpgqak5dfn86VO0Gn3Kt6XgSH/iN5VqFn1i31FAb4ZIMsx+oms9dumhwZdv5JAAAAEkGa4UnhDomUwIZf/p4QAAAGBAAAAOVBAPea4UnhDomUwIZf/p4QAAWzmXSGMwPes+kYWQAHOauaggKUVsXqLojDpE/9B3djsqyBkGOiBaEbqN3w/fuJj1H2k3bc8Ub5GXvb3aXK1XuH+DBkB2IChhykYNO14r7kuDHecGz0otUieABQbfek9/Ilm3CyzQ/nFrMR1zhpkDsEwVAB60VGaPKBMQx9A2DbnYJvQtuRdIIcR/wBaPul1OhOeFHQzhVfTbTYq7c2RxZcKUEoWxnEvGHYz7PWmi6SHYqALgyZ9ARSVH1go4LrnbgCaYJIms/lI+J7kU9fSkXL3vxqAAAAEkGbAknhDyZTAhl//p4QAAAGBQAAANhBAPebAknhDyZTAhl//p4QAAX3+p7gK/qrIAE1Zxaqvrm3wTmZ0LJc9gHm2fVMlFOejO5Um2egGindz99UpmICfq2YbRbT9wRn7m9sBxl9+gzuuBZlZHFmlww8ciQV2c2Kt0JZ9XXdVT6zB3yVOSfbx3WJbjV6o3YOYdnc/sN+6tlFqFNCmKXR4k8j1ULbWMdN61SMw/HDBvC8hB8J6YwXuN6EVrQmBLgF3U9ybQkI5Pf0Lz7pW+ZX+zw29qXt4wMbBQpUbO5FeB/p8NSgy6COjBjIWKoz9eEAAAASQZsmSeEPJlMCF3/+jLAAAAYMAAAAcUEA95smSeEPJlMCF3/+jLAABgFsmxRFreBoGnULeefhtsOqqJZ2gAg4C5kX+h/JC4DI19bfEX6H/N/GXbNdSu1wL4YWo/E/axKNVSaShyIfw76i1mbCu30u1pDOkiEFCetbhrtycznS31a3kX3FWzzIAAAADUGfREURPCr/AAADAUEAAADCQQD3n0RFETwq/wB7FHNCrHfnvhUsdZl3dukAJz7ZJOLNzAcVCMqBt31Pe7MYSAqddfvTYgLIu6SsUoQ+c/ZprwEuSiI3s44mqASJ9itpGK65dSRFxEJh6zz5+eBUq/meMS4GqrpZ1ATKa8XZ3t3dIRb8qsr89Zrgxffv7tt3prh3OI6iswYkoXEp1MyPmNTnflrjnCg6fZMKMRdERCf0vPeLtxMghXzZtRP1lwHGPHhyeGCtukvxQd+xdr5lh7aE7oEAAAALAZ9jdEJvAAADAZ8AAABqAQD3n2N0Qm8AAZtFVVPt7kM7Vpgvl8IY4uyABs+lru8fwrRap/FPAA8p2UEU8QtNhoBwbjahZyNReHoMIH69IOKWJCCHBCN4G5DwajMkwhvgPKDnM50fd21VgEv+EkHiHpfiaNTAv5CM6QAAAAsBn2VqQm8AAAMBnwAAAGABAPefZWpCbwABmoTxTqyFKUPrIoJm7oPcFOIFgQIpmQQjELqIVKwkACcadhVMSf7aNig0KiNUAcmlUPEsc9Gue8YWgParqrIZUBz1Cmj+fRzlQ9iUK3GU7a501X3tToEAAAAVQZtoSahBaJlMFPCb//3xAAADADjhAAAAmEEA95toSahBaJlMFPCb//3xAAA43puY0rJvenPzwA34AQeC9NK7WlqN3mDE0Z1Ix3cKDcMVEmkRqna/ilWkmOU5HLe0ZxNiZS7MKXu4t+usf+bKkOHUXpepQtAxpk12923PHMw2dU9XypOEsFdk2eblm5bd25ptkFz70uYjwxInWy3j742dczD3WHPHWjgSMYnjfsGy/2CJAAAACwGfh2pCbwAAAwGfAAAAawEA95+HakJvAKP5v1nNOy2GJm6Rla9oARe6UBN9SCD8yqrV2rQmSsvTnB0TLA3dwIUz+uZvDYPMiUSmbfb2/jXtNQ3+LOVQrIRZEhwB2jm9HUMhsgiUZjPLoNOCZ2uhjlZq2w4bpT7RK1XLAAAEzm1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAAVXAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAP5dHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAAVXAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAJYAAABkAAAAAAAJGVkdHMAAAAcZWxzdAAAAAAAAAABAAAFVwAABAAAAQAAAAADcW1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAPAAAAFIAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAAAxxtaW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAALcc3RibAAAALBzdHNkAAAAAAAAAAEAAACgYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAJYAZAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAADZhdmNDAWQAHv/hABlnZAAerNlAmDPl4QAAAwABAAADADwPFi2WAQAGaOvjyyLA/fj4AAAAABRidHJ0AAAAAAABBEIAAAAAAAAAGHN0dHMAAAAAAAAAAQAAACkAAAIAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAEQY3R0cwAAAAAAAAAgAAAAAQAABAAAAAABAAAGAAAAAAEAAAIAAAAAAgAABAAAAAABAAAGAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAEAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAIAAAAAAIAAAIAAAAABQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAAEAAAEAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAKQAAAAEAAAC4c3RzegAAAAAAAAAAAAAAKQAAEHwAAAGUAAAAgQAAAM8AAADhAAABKQAAAHgAAAChAAAAigAAAH4AAABzAAAAygAAAUYAAACEAAAAlQAAAHcAAABFAAAA1QAAAMcAAAD/AAAA8gAAANEAAADKAAAAfwAAAFwAAACPAAAA3wAAAQ4AAABqAAAAZgAAAG8AAAC1AAAAqgAAAP8AAADyAAAAiwAAANcAAAB9AAAAcwAAALUAAAB+AAAAFHN0Y28AAAAAAAAAAQAAADAAAABhdWR0YQAAAFltZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAACxpbHN0AAAAJKl0b28AAAAcZGF0YQAAAAEAAAAATGF2ZjYxLjcuMTAw\" type=\"video/mp4\">\n",
       " Your browser does not support the video tag.\n",
       " </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "# explicitly grab the first worker's env and dump its transform\n",
    "# after your rollout / training loop\n",
    "rec_env.transform.dump()\n",
    "Video(str(VIDEO_DIR / \"only_video_0.mp4\"), embed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21xeQyutZmEW"
   },
   "source": [
    "### Creating a SyncDataCollector\n",
    "\n",
    "TorchRL provides a set of `DataCollector` classes. These manage three actions: Reset an environment, compute an action given the latest observation, execute a step in an environment. It can repeat the last two steps until the environment signals a stop or done state.\n",
    "\n",
    "This is a very powerful tool that will allow you to control how many frames to collect at each iteration, when to reset the environment and which device to run our neural networks on.\n",
    "\n",
    "Think of it as a very powerful DataLoader class for RL.\n",
    "\n",
    "\n",
    "### What is stop state vs done state?\n",
    "Stop state: We reached the max number of frames that the environment can handle/or we defined in an episode, so it truncates.\n",
    "\n",
    "Done state: We reached the goal for that episode! (yay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1746503028132,
     "user": {
      "displayName": "SOC AI SOCIETY",
      "userId": "14965631179156013617"
     },
     "user_tz": -480
    },
    "id": "c_iu9Fpla2Wi"
   },
   "outputs": [],
   "source": [
    " collector = SyncDataCollector(\n",
    "    composed_env,\n",
    "    value_module,\n",
    "    frames_per_batch=frames_per_batch,\n",
    "    total_frames=total_frames,\n",
    "    split_trajs=False,\n",
    "    reset_at_each_iter=False,\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmV7ARBoak5I"
   },
   "source": [
    "### Replay buffers\n",
    "\n",
    "Replay buffers are used to store data after being collected by the DataCollector, as the model will repeatedly consume this data for a certain number of epoch before moving to the next epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1746503031207,
     "user": {
      "displayName": "SOC AI SOCIETY",
      "userId": "14965631179156013617"
     },
     "user_tz": -480
    },
    "id": "3hGXc3tLa4nC"
   },
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer(\n",
    "    storage=LazyTensorStorage(max_size=frames_per_batch),\n",
    "    sampler=SamplerWithoutReplacement(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75z8ZS7-bjvh"
   },
   "source": [
    "### Loss\n",
    "\n",
    "Over here, we initialised the DQN LOSS using the actor and critic loss, and removed advantage.\n",
    "\n",
    "Observe that by using TorchRL, most of our code has stayed intact, and only our loss has changed. That is the beauty of TorchRL, as we get to keep the structure of our code and just change small parts of the original code in order to experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1746503034660,
     "user": {
      "displayName": "SOC AI SOCIETY",
      "userId": "14965631179156013617"
     },
     "user_tz": -480
    },
    "id": "79NhkZdga5hQ"
   },
   "outputs": [],
   "source": [
    "loss_module = DQNLoss(value_module, action_space=spec)\n",
    "\n",
    "optim = torch.optim.Adam(loss_module.parameters(), lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optim, total_frames // frames_per_batch, 0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egDBCs_CeG98"
   },
   "source": [
    "### Do a dummy forward pass\n",
    "\n",
    "Remember that we used LazyLinear? Well before we can actually start training, we need to do a dummy forward pass here to make sure all the input shapes are initialised, lest we get errors (and we will get an error if this is not done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1746503035908,
     "user": {
      "displayName": "SOC AI SOCIETY",
      "userId": "14965631179156013617"
     },
     "user_tz": -480
    },
    "id": "I--3h7cVKTO7"
   },
   "outputs": [],
   "source": [
    "dummy_td = composed_env.reset()\n",
    "dummy_observation = dummy_td[\"observation\"].unsqueeze(0)\n",
    "# Run a dummy forward pass through the actor network\n",
    "# If your actor network expects the observation in a dict form, wrap it accordingly.\n",
    "_ = value_module(dummy_observation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psP7Glh9dj8y"
   },
   "source": [
    "### Training Loop:\n",
    "\n",
    "To train our DQN model on MountainCar-v0, we will go through a few steps:\n",
    "\n",
    "1. Collect the data by looping through our DataCollector\n",
    "1. Since we are using ParallelEnv, we must account for the total number of frames across ALL environments\n",
    "1. For num_epochs:\n",
    "  1. Add the data to our replay buffer and train our value network on the data for num_epochs\n",
    "  1. Update gradient_steps based on sub batch defined at the start\n",
    "  1. Calculate losses and backprop\n",
    "1. Log data\n",
    "1. Store recording as a file\n",
    "1. Repeat til done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "7db71ec870504790a3ffa207cb532c0f",
      "d326226ef44f4252beae83ea47664d7a",
      "5fae39e65b284cfc8efe746ae0739da4",
      "8755ea1d27e548ccba143a3d16e670b6",
      "0c777e17078a48a3b2e1e12870c3ebd1",
      "e640c935793a4f9b8e640b4528d893ce",
      "4116f085654a474ba0dfcef6bc8bc468",
      "ad969f83edeb4fdc8b7eb2500c04c015",
      "574ce6e364514205b0cfb8f9f00c8fa3",
      "6525fc8b90404b498e05f4d419e7e226",
      "c86a870a708349b89abd0192f3952ae5"
     ]
    },
    "executionInfo": {
     "elapsed": 682780,
     "status": "ok",
     "timestamp": 1746503745495,
     "user": {
      "displayName": "SOC AI SOCIETY",
      "userId": "14965631179156013617"
     },
     "user_tz": -480
    },
    "id": "XCGT4ynSa7Kg",
    "outputId": "404eb214-147a-4954-b624-29cdbf43e59d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db71ec870504790a3ffa207cb532c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logs = defaultdict(list)\n",
    "pbar = tqdm(total=total_frames) # Set up the progress bar\n",
    "eval_str = \"\"\n",
    "\n",
    "# We iterate over the collector until it reaches the total number of frames it was\n",
    "# designed to collect:\n",
    "for i, tensordict_data in enumerate(collector):\n",
    "    # tensordict_data now has shape [time, num_envs, ...] with parallel environments\n",
    "\n",
    "    # Calculate total frames in this batch (accounting for parallel environments)\n",
    "    current_batch_size = tensordict_data.shape[0] * tensordict_data.shape[1]\n",
    "\n",
    "    for _ in range(num_epochs):\n",
    "\n",
    "        # Reshape to flatten time and env dimensions together\n",
    "        # From [time, num_envs, ...] to [time*num_envs, ...]\n",
    "        data_view = tensordict_data.view(-1)\n",
    "        replay_buffer.extend(data_view.cpu())\n",
    "\n",
    "        # Adjust number of gradient steps based on total experiences collected\n",
    "        num_grad_steps = current_batch_size // sub_batch_size\n",
    "        for _ in range(num_grad_steps):\n",
    "            subdata = replay_buffer.sample(sub_batch_size).to(DEVICE)\n",
    "            loss_vals = loss_module(subdata.to(DEVICE))\n",
    "            loss_value = loss_vals[\"loss\"]\n",
    "\n",
    "            loss_value.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(loss_module.parameters(), max_grad_norm)\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "    # Compute metrics across all environments\n",
    "    # Average reward across both time and environments\n",
    "    logs[\"reward\"].append(tensordict_data[\"next\", \"reward\"].mean().item())\n",
    "\n",
    "    # Update progress bar with total frames processed in this batch\n",
    "    pbar.update(tensordict_data.numel())\n",
    "\n",
    "    cum_reward_str = (\n",
    "        f\"average reward={logs['reward'][-1]: 4.4f} (init={logs['reward'][0]: 4.4f})\"\n",
    "    )\n",
    "\n",
    "    # For step count, take max across all environments\n",
    "    logs[\"step_count\"].append(tensordict_data[\"step_count\"].max().item())\n",
    "    stepcount_str = f\"step count (max): {logs['step_count'][-1]}\"\n",
    "\n",
    "    logs[\"lr\"].append(optim.param_groups[0][\"lr\"])\n",
    "    lr_str = f\"lr policy: {logs['lr'][-1]: 4.4f}\"\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        with set_exploration_type(ExplorationType.DETERMINISTIC), torch.no_grad():\n",
    "            # Execute rollout with all parallel environments\n",
    "            eval_rollout = rec_env.rollout(1000, value_module)\n",
    "            rec_env.transform.dump()\n",
    "\n",
    "            # Average reward across environments\n",
    "            logs[\"eval reward\"].append(eval_rollout[\"next\", \"reward\"].mean().item())\n",
    "\n",
    "            # Sum across time, then average across environments\n",
    "            # This handles multiple environment trajectories properly\n",
    "            sum_rewards = eval_rollout[\"next\", \"reward\"].sum(dim=0).mean().item()\n",
    "            logs[\"eval reward (sum)\"].append(sum_rewards)\n",
    "\n",
    "            logs[\"eval step_count\"].append(eval_rollout[\"step_count\"].max().item())\n",
    "            eval_str = (\n",
    "                f\"eval cumulative reward: {logs['eval reward (sum)'][-1]: 4.4f} \"\n",
    "                f\"(init: {logs['eval reward (sum)'][0]: 4.4f}), \"\n",
    "                f\"eval step-count: {logs['eval step_count'][-1]}\"\n",
    "            )\n",
    "            del eval_rollout\n",
    "\n",
    "    pbar.set_description(\", \".join([eval_str, cum_reward_str, stepcount_str, lr_str]))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85XRveVLfb07"
   },
   "source": [
    "### Visualise Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "aborted",
     "timestamp": 1746503044333,
     "user": {
      "displayName": "SOC AI SOCIETY",
      "userId": "14965631179156013617"
     },
     "user_tz": -480
    },
    "id": "sB6eKWioa9QO"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(logs[\"reward\"])\n",
    "plt.title(\"training rewards (average)\")\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(logs[\"step_count\"])\n",
    "plt.title(\"Max step count (training)\")\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(logs[\"eval reward (sum)\"])\n",
    "plt.title(\"Return (test)\")\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(logs[\"eval step_count\"])\n",
    "plt.title(\"Max step count (test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1746503048538,
     "user": {
      "displayName": "SOC AI SOCIETY",
      "userId": "14965631179156013617"
     },
     "user_tz": -480
    },
    "id": "r0pS_l44OBzz",
    "outputId": "6280f4a8-b0a6-4bb3-c235-6e2160e0c42a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only_video_0.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video controls  >\n",
       " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
       " Your browser does not support the video tag.\n",
       " </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "#Visualise with video\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower()\n",
    "            for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "\n",
    "print(sorted(os.listdir(VIDEO_DIR), key = natural_sort_key)[-1])\n",
    "Video(VIDEO_DIR/sorted(os.listdir(VIDEO_DIR), key = natural_sort_key)[-1], embed = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5F9ZgNAnH3Q6"
   },
   "source": [
    "### Further resources\n",
    "\n",
    "How to debug your RL Model: https://pytorch.org/rl/main/reference/generated/knowledge_base/DEBUGGING_RL.html"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1PvLXQZDodiADpQeiQWXUTUbeahE1Gz_e",
     "timestamp": 1745429228858
    },
    {
     "file_id": "19s_GSBrhjmNeud2hHaDSXTRSkAc8uasI",
     "timestamp": 1745426113127
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0c777e17078a48a3b2e1e12870c3ebd1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4116f085654a474ba0dfcef6bc8bc468": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "574ce6e364514205b0cfb8f9f00c8fa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5fae39e65b284cfc8efe746ae0739da4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad969f83edeb4fdc8b7eb2500c04c015",
      "max": 250000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_574ce6e364514205b0cfb8f9f00c8fa3",
      "value": 248124
     }
    },
    "6525fc8b90404b498e05f4d419e7e226": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7db71ec870504790a3ffa207cb532c0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d326226ef44f4252beae83ea47664d7a",
       "IPY_MODEL_5fae39e65b284cfc8efe746ae0739da4",
       "IPY_MODEL_8755ea1d27e548ccba143a3d16e670b6"
      ],
      "layout": "IPY_MODEL_0c777e17078a48a3b2e1e12870c3ebd1"
     }
    },
    "8755ea1d27e548ccba143a3d16e670b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6525fc8b90404b498e05f4d419e7e226",
      "placeholder": "​",
      "style": "IPY_MODEL_c86a870a708349b89abd0192f3952ae5",
      "value": " 248124/250000 [11:36&lt;00:05, 321.97it/s]"
     }
    },
    "ad969f83edeb4fdc8b7eb2500c04c015": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c86a870a708349b89abd0192f3952ae5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d326226ef44f4252beae83ea47664d7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e640c935793a4f9b8e640b4528d893ce",
      "placeholder": "​",
      "style": "IPY_MODEL_4116f085654a474ba0dfcef6bc8bc468",
      "value": "eval cumulative reward:  0.8092 (init:  0.9534), eval step-count: 199, average reward= 0.0194 (init= 0.0247), step count (max): 199, lr policy:  0.0000:  99%"
     }
    },
    "e640c935793a4f9b8e640b4528d893ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
